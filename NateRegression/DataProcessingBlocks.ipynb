{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7474553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure to confirm that the following path is the correct working directory\n",
      "/Users/dsnyder/Documents/GitHub/wind-model/NateRegression\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "print('Make sure to confirm that the following path is the correct working directory')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71754e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define speeds (m/s) corresponding to 0-40 Hz settings in wind tunnel\n",
    "### (Just for record-keeping)\n",
    "hzArray = np.array((0, 5, 10, 15, 20, 25, 30, 35, 40))\n",
    "speeds = np.array((0.00, 1.26363735, 1.58562983, 2.07066356, 2.571993, 3.18291372, 3.75322345, 4.33626595, 4.91413509))\n",
    "###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1ca7a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "6\n",
      "\n",
      "7\n",
      "\n",
      "8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Master Import Block (2-Degree Increments) [I of II]\n",
    "\n",
    "Because the data is so large, we assume that at any point, only a single \n",
    "speed's worth of data is available (i.e. 180 files + the relevant 0-speed readings for a single, fixed Hz). \n",
    "This can be toggled by increasing the nVel parameter, but is NOT recommended (i.e., keep nVel = 1). \n",
    "\n",
    "\n",
    "PARAMETERS: \n",
    "\n",
    "startIdx -- int -- in {1, ..., 8}, represents the lowest Hz we are importing; Hz value is 5*startIdx. \n",
    "nVel     -- int -- in {1, ..., 8}, represents how many sequential Hz we are importing\n",
    "\n",
    "nTrain   -- int -- number of training points at EACH velocity and angle to end up with\n",
    "nTest    -- int -- number of testing points at EACH velocity and angle to end up with\n",
    "N        -- int -- number of points to average over PER datum (effective sampling rate is nominal_rate/N)\n",
    "numAng   -- int -- number of angle increments present in the data; should be a divisor of 360\n",
    "numVel   -- int -- number of different Hz total\n",
    "M        -- int -- number of rows of each file to sample (smaller = faster)\n",
    "\n",
    "[TODO]: add a moving-average filter as a possible modification to the data input reading / filtering problem.\n",
    "\n",
    "\n",
    "RESULT: \n",
    "\n",
    "Output (after manually cycling through numVel instances) is equal to numVel files of mags, angs, angsrad, \n",
    "and readings. These are combined in the next block. \n",
    "'''\n",
    "\n",
    "# raise ValueError('Do not run if you already have the csv data!')\n",
    "\n",
    "# raise ValueError('Make sure to confirm file path at bottom of this block!')\n",
    "\n",
    "#\n",
    "# BEGIN Parameters to alter by the user\n",
    "#\n",
    "\n",
    "oneGo = True\n",
    "# Designed to be iterable by simply changing startIdx with everything else fixed\n",
    "\n",
    "startIdx = 1\n",
    "nVel = 8\n",
    "\n",
    "# Choose geometry (nKeep: hexagon = 6, pentagon = 5, square = 4, triangle = 3...)\n",
    "nInputs = 6\n",
    "geo = 'hex/'\n",
    "nKeep = 6\n",
    "\n",
    "nTrain = 500\n",
    "nValidate = 200\n",
    "nTest = 200\n",
    "N = 5              # Number of points to average over\n",
    "deltaN = 20        # How many to skip per sample --> Must be AT LEAST as big as N!\n",
    "numAng = 180       # For 10-degree increments set this to 36 instead of 180\n",
    "numVel = 8\n",
    "\n",
    "np.random.seed(12345*N)\n",
    "\n",
    "dataPath = 'data/'\n",
    "trainPath = 'fooTrain/N'+str(N)+'/'\n",
    "testPath = 'fooTest/N'+str(N)+'/'\n",
    "valPath = 'fooVal/N'+str(N)+'/'\n",
    "\n",
    "outTrainPath = 'compTrain_N'+str(N)+'/'+geo\n",
    "outTestPath = 'compTest_N'+str(N)+'/'+geo\n",
    "outValPath = 'compVal_N'+str(N)+'/'+geo\n",
    "#\n",
    "# END Parameters to alter by the user\n",
    "#\n",
    "\n",
    "#\n",
    "# BEGIN derived parameters\n",
    "# \n",
    "numTrain = nTrain*(deltaN+1)         # End up with nTrain train points which represent averages over N consecutive samples\n",
    "numValidate = nValidate*(deltaN+1)   # End up with nValidate validation points (each averages over N consecutive samples)\n",
    "numTest = nTest*(deltaN+1)           # End up with nTest test points which represent averages over N consecutive samples\n",
    "\n",
    "M = 6000 + numTrain + numValidate + numTest\n",
    "\n",
    "skip1 = 1000 + int(np.floor(np.random.rand()*800))\n",
    "skip2 = 1000 + int(np.floor(np.random.rand()*800))\n",
    "\n",
    "kAng = int(360/numAng)\n",
    "kVel = int(40/numVel)\n",
    "\n",
    "RTL = M - numTrain - numValidate - numTest - 4000\n",
    "RTH = RTL + numTest\n",
    "RL0 = RTH + skip1\n",
    "RH0 = RL0 + numValidate\n",
    "RL = RH0 + skip2\n",
    "RH = RL + numTrain\n",
    "\n",
    "if RH > M:\n",
    "    # Error checking. We want to min M (faster read-in, less wasteful), but also need to sample and \n",
    "    # leave some offset between train and test to prevent overfitting to temporal correlations\n",
    "    raise ValueError('RH larger than max_rows (M)! Need to increase M or reduce {N, nTrain, nTest}')\n",
    "\n",
    "# \n",
    "# END derived parameters \n",
    "# \n",
    "\n",
    "#\n",
    "# BEGIN storage arrays to be written out at the end\n",
    "# \n",
    "df = np.zeros((numAng*nVel*nTrain, nKeep))\n",
    "dfT = np.zeros((numAng*nVel*nTest, nKeep))\n",
    "dfV = np.zeros((numAng*nVel*nValidate, nKeep))\n",
    "mags = np.zeros(numAng*nVel*nTrain)\n",
    "angs = np.zeros(numAng*nVel*nTrain)\n",
    "magsT = np.zeros(numAng*nVel*nTest)\n",
    "angsT = np.zeros(numAng*nVel*nTest)\n",
    "magsV = np.zeros(numAng*nVel*nValidate)\n",
    "angsV = np.zeros(numAng*nVel*nValidate)\n",
    "\n",
    "\n",
    "tmpf = np.zeros((nTrain, nKeep))\n",
    "tmpft = np.zeros((nTest, nKeep))\n",
    "tmpfv = np.zeros((nValidate, nKeep))\n",
    "#\n",
    "# END storage arrays to be written out at the end\n",
    "# \n",
    "\n",
    "# Iterate over the set of velocities (startIdx to startIdx + nVel)\n",
    "for hz in range(startIdx, startIdx+nVel):\n",
    "    # Import the zero-speed data as to difference from the data with velocity\n",
    "    if nKeep == 5:\n",
    "        zeroDataStr = 'zeros'+str(hz)+'_angle_0_samples_30000_frequency_1000_motor_0_Hz.txt'\n",
    "    elif nKeep == 6:\n",
    "        zeroDataStr = 'calibData'+str(hz)+'_angle_0_samples_30000_frequency_1000_motor_0_Hz.txt'\n",
    "    else: \n",
    "        raise ValueError('Unsupported nKeep as of June 27 2022')\n",
    "        \n",
    "    # For hexagon: 'calibData_angle_0_samples_30000_frequency_1000_motor_0_Hz.txt'\n",
    "    # For pentagon: 'zeros'+str(hz)+'_angle_0_samples_30000_frequency_1000_motor_0_Hz.txt'\n",
    "    \n",
    "    txtString2 = dataPath+zeroDataStr\n",
    "    df1 = np.loadtxt(txtString2, skiprows=1, max_rows=M, delimiter=',')\n",
    "\n",
    "    # Keep tabs on progress by printing hz value\n",
    "    print(hz)\n",
    "    print()\n",
    "    # Iterate over the set of angles (numAng)\n",
    "    # Assumed to be saved in even degree intervals (e.g. 10 degrees, 2 degrees, etc)\n",
    "    for ang in range(numAng): \n",
    "        # Load the data and difference with zero-velocity readings\n",
    "        # For Hexagon:\n",
    "        # txtString = dataPath+'calibData_angle_' + str(int(ang*kAng)) + '_samples_30000_frequency_1000_motor_'+str(int(hz*kVel))+'_Hz.txt'\n",
    "        # For Pentagon: \n",
    "        # txtString = dataPath+'data_degInc_2_angle_' + str(int(ang*kAng)) + '_samples_30000_frequency_1000_motor_'+str(int(hz*kVel))+'_Hz.txt'\n",
    "        if nKeep == 5:\n",
    "            txtString = dataPath+'data_degInc_2_angle_' + str(int(ang*kAng)) + '_samples_30000_frequency_1000_motor_'+str(int(hz*kVel))+'_Hz.txt'\n",
    "        elif nKeep == 6:\n",
    "            txtString = dataPath+'calibData_angle_' + str(int(ang*kAng)) + '_samples_30000_frequency_1000_motor_'+str(int(hz*kVel))+'_Hz.txt'\n",
    "        else: \n",
    "            raise ValueError('Unsupported nKeep as of June 27 2022 - must be 5 or 6')\n",
    "        \n",
    "        df0 = np.loadtxt(txtString, skiprows=1, max_rows=M, delimiter=',')\n",
    "        \n",
    "        # Pick out training, validation, and test data segments\n",
    "        tmpf0 = (df0[RL:RH,:nKeep] - df1[RL:RH,:nKeep])\n",
    "        tmpft0 = (df0[RTL:RTH,:nKeep] - df1[RTL:RTH,:nKeep])\n",
    "        tmpfv0 = (df0[RL0:RH0,:nKeep] - df1[RL0:RH0,:nKeep])\n",
    "        \n",
    "        # Perform the filtering (averaging), condensing from {numTrain, numTest} to {nTrain, nTest}\n",
    "        for k in range(nTrain):\n",
    "            tmpf[k,:] = np.mean(tmpf0[deltaN*k:deltaN*k+N,:], axis=0)\n",
    "            if k < nTest:\n",
    "                tmpft[k,:] = np.mean(tmpft0[deltaN*k:deltaN*k+N,:], axis=0)\n",
    "            if k < nValidate:\n",
    "                tmpfv[k,:] = np.mean(tmpfv0[deltaN*k:deltaN*k+N,:], axis=0)\n",
    "        \n",
    "        # Put the (nTrain, 6), (nTest, 6) arrays into the larger df, dfT arrays in the right spot\n",
    "        # This represents the train/test features (X)\n",
    "        df[(numAng*nTrain*(hz-startIdx)+ang*nTrain):(numAng*nTrain*(hz-startIdx)+(ang+1)*nTrain),:nKeep] = tmpf\n",
    "        dfT[(numAng*nTest*(hz-startIdx)+ang*nTest):(numAng*nTest*(hz-startIdx)+(ang+1)*nTest),:nKeep] = tmpft\n",
    "        dfV[(numAng*nValidate*(hz-startIdx)+ang*nValidate):(numAng*nValidate*(hz-startIdx)+(ang+1)*nValidate),:nKeep] = tmpfv\n",
    "        \n",
    "        # Put the (ntrain, ) (nTest, ) arrays into the larger angs, mags, angsT, magsT in the right spot\n",
    "        # This represents the train/test labels (y)\n",
    "        angs[(numAng*nTrain*(hz-startIdx)+ang*nTrain):(numAng*nTrain*(hz-startIdx)+(ang+1)*nTrain)] = ang*kAng*np.ones(nTrain) # Angles in degrees\n",
    "        mags[(numAng*nTrain*(hz-startIdx)+ang*nTrain):(numAng*nTrain*(hz-startIdx)+(ang+1)*nTrain)] = speeds[hz]*np.ones(nTrain)\n",
    "        angsT[(numAng*nTest*(hz-startIdx)+ang*nTest):(numAng*nTest*(hz-startIdx)+(ang+1)*nTest)] = ang*kAng*np.ones(nTest) # Angles in degrees\n",
    "        magsT[(numAng*nTest*(hz-startIdx)+ang*nTest):(numAng*nTest*(hz-startIdx)+(ang+1)*nTest)] = speeds[hz]*np.ones(nTest)\n",
    "        angsV[(numAng*nValidate*(hz-startIdx)+ang*nValidate):(numAng*nValidate*(hz-startIdx)+(ang+1)*nValidate)] = ang*kAng*np.ones(nValidate) # Angles in degrees\n",
    "        magsV[(numAng*nValidate*(hz-startIdx)+ang*nValidate):(numAng*nValidate*(hz-startIdx)+(ang+1)*nValidate)] = speeds[hz]*np.ones(nValidate)\n",
    "        \n",
    "\n",
    "    \n",
    "'''\n",
    "Once we have finished, write the results to files\n",
    "This allows us to index files by the idx of the run\n",
    "Here, we assume nVel = 1\n",
    "'''\n",
    "if oneGo:\n",
    "    np.savetxt(outTrainPath+'readings.csv', df, delimiter=',')\n",
    "    np.savetxt(outTrainPath+'mags.csv', mags, delimiter=',')\n",
    "    np.savetxt(outTrainPath+'angs.csv', angs, delimiter=',')\n",
    "\n",
    "    np.savetxt(outTestPath+'readings.csv', dfT, delimiter=',')\n",
    "    np.savetxt(outTestPath+'mags.csv', magsT, delimiter=',')\n",
    "    np.savetxt(outTestPath+'angs.csv', angsT, delimiter=',')\n",
    "\n",
    "    np.savetxt(outValPath+'readings.csv', dfV, delimiter=',')\n",
    "    np.savetxt(outValPath+'mags.csv', magsV, delimiter=',')\n",
    "    np.savetxt(outValPath+'angs.csv', angsV, delimiter=',')\n",
    "    \n",
    "    np.savetxt(outTrainPath+'angsrad.csv', angs*math.pi/180.0, delimiter=',')\n",
    "    np.savetxt(outTestPath+'angsrad.csv', angsT*math.pi/180.0, delimiter=',')\n",
    "    np.savetxt(outValPath+'angsrad.csv', angsV*math.pi/180.0, delimiter=',')\n",
    "    \n",
    "else:\n",
    "    np.savetxt(trainPath+'readings'+str(startIdx)+'.csv', df, delimiter=',')\n",
    "    np.savetxt(trainPath+'mags'+str(startIdx)+'.csv', mags, delimiter=',')\n",
    "    np.savetxt(trainPath+'angs'+str(startIdx)+'.csv', angs, delimiter=',')\n",
    "\n",
    "    np.savetxt(testPath+'readings'+str(startIdx)+'.csv', dfT, delimiter=',')\n",
    "    np.savetxt(testPath+'mags'+str(startIdx)+'.csv', magsT, delimiter=',')\n",
    "    np.savetxt(testPath+'angs'+str(startIdx)+'.csv', angsT, delimiter=',')\n",
    "\n",
    "    np.savetxt(valPath+'readings'+str(startIdx)+'.csv', dfV, delimiter=',')\n",
    "    np.savetxt(valPath+'mags'+str(startIdx)+'.csv', magsV, delimiter=',')\n",
    "    np.savetxt(valPath+'angs'+str(startIdx)+'.csv', angsV, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc4cd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Master Import Block (2-Degree Increments) [II of II]\n",
    "\n",
    "Because the data is so large, we assume that at any point, only a single \n",
    "speed's worth of data is available (i.e. 180 files + the relevant 0-speed readings for a single, fixed Hz). \n",
    "This can be toggled by increasing the nVel parameter, but is NOT recommended (i.e., keep nVel = 1). \n",
    "\n",
    "\n",
    "INPUT: \n",
    "\n",
    "numVel files each of mags, angs, angsrad, and readings, named with iterated numbers from 1 to numVel. \n",
    "\n",
    "REQUIREMENTS: \n",
    "\n",
    "Parameters from Master Block I in the workspace, specifically: \n",
    "\n",
    "     nTrain\n",
    "     nTest\n",
    "     numAng\n",
    "     numVel\n",
    "\n",
    "OUTPUT: \n",
    "\n",
    "A single concatenated file for each of mags, angs, angsrad, and readings, which preserves proper labeling. \n",
    "'''\n",
    "\n",
    "# raise ValueError('Confirm that you actually need to run this function!')\n",
    "\n",
    "# raise ValueError('Check the path of the written files, below!')\n",
    "dataPath = 'data/'\n",
    "trainPath = 'fooTrain/N'+str(N)+'/'\n",
    "testPath = 'fooTest/N'+str(N)+'/'\n",
    "valPath = 'fooVal/N'+str(N)+'/'\n",
    "\n",
    "geo = 'pent/'\n",
    "\n",
    "outTrainPath = 'compTrain_N'+str(N)+'/'+geo\n",
    "outTestPath = 'compTest_N'+str(N)+'/'+geo\n",
    "outValPath = 'compVal_N'+str(N)+'/'+geo\n",
    "\n",
    "if oneGo:\n",
    "        \n",
    "    angs = (pd.read_csv(trainPath+'angs'+str(1)+'.csv', header=None)).to_numpy()[:,0]\n",
    "    angsT = (pd.read_csv(testPath+'angs'+str(1)+'.csv', header=None)).to_numpy()[:,0]\n",
    "    angsV = (pd.read_csv(valPath+'angs'+str(1)+'.csv', header=None)).to_numpy()[:,0]\n",
    "\n",
    "    #np.savetxt(outTrainPath+'angs.csv', angs, delimiter=',')\n",
    "    np.savetxt(outTrainPath+'angsrad.csv', angs*math.pi/180.0, delimiter=',')\n",
    "    #np.savetxt(outTestPath+'angs.csv', angsT, delimiter=',')\n",
    "    np.savetxt(outTestPath+'angsrad.csv', angsT*math.pi/180.0, delimiter=',')\n",
    "    #np.savetxt(outValPath+'angs.csv', angsV, delimiter=',')\n",
    "    np.savetxt(outValPath+'angsrad.csv', angsV*math.pi/180.0, delimiter=',')\n",
    "else:\n",
    "\n",
    "    df = np.zeros((numAng*numVel*nTrain, nKeep))\n",
    "    dfT = np.zeros((numAng*numVel*nTest, nKeep))\n",
    "    dfV = np.zeros((numAng*numVel*nValidate, nKeep))\n",
    "    \n",
    "    angs = np.zeros(numAng*numVel*nTrain)\n",
    "    angsT = np.zeros(numAng*numVel*nTest)\n",
    "    angsV = np.zeros(numAng*numVel*nValidate)\n",
    "\n",
    "    mags = np.zeros(numAng*numVel*nTrain)\n",
    "    magsT = np.zeros(numAng*numVel*nTest)\n",
    "    magsV = np.zeros(numAng*numVel*nValidate)\n",
    "\n",
    "\n",
    "    for k in range(1, 1+numVel):\n",
    "        print(k)\n",
    "        df[numAng*nTrain*(k-1):numAng*nTrain*k,:] = (pd.read_csv(trainPath+'readings'+str(k)+'.csv', header=None)).to_numpy()\n",
    "        mags[numAng*nTrain*(k-1):numAng*nTrain*k] = (pd.read_csv(trainPath+'mags'+str(k)+'.csv', header=None)).to_numpy()[:,0]\n",
    "        angs[numAng*nTrain*(k-1):numAng*nTrain*k] = (pd.read_csv(trainPath+'angs'+str(k)+'.csv', header=None)).to_numpy()[:,0]\n",
    "\n",
    "        dfT[numAng*nTest*(k-1):numAng*nTest*k,:] = (pd.read_csv(testPath+'readings'+str(k)+'.csv', header=None)).to_numpy()\n",
    "        magsT[numAng*nTest*(k-1):numAng*nTest*k] = (pd.read_csv(testPath+'mags'+str(k)+'.csv', header=None)).to_numpy()[:,0]\n",
    "        angsT[numAng*nTest*(k-1):numAng*nTest*k] = (pd.read_csv(testPath+'angs'+str(k)+'.csv', header=None)).to_numpy()[:,0]\n",
    "\n",
    "        dfV[numAng*nValidate*(k-1):numAng*nValidate*k,:] = (pd.read_csv(valPath+'readings'+str(k)+'.csv', header=None)).to_numpy()\n",
    "        magsV[numAng*nValidate*(k-1):numAng*nValidate*k] = (pd.read_csv(valPath+'mags'+str(k)+'.csv', header=None)).to_numpy()[:,0]\n",
    "        angsV[numAng*nValidate*(k-1):numAng*nValidate*k] = (pd.read_csv(valPath+'angs'+str(k)+'.csv', header=None)).to_numpy()[:,0]\n",
    "\n",
    "\n",
    "    \n",
    "    # Save the files in the desired format. \n",
    "    # The old files loaded above can be kept or manually removed\n",
    "    print('Saving files!')\n",
    "\n",
    "    np.savetxt(outTrainPath+'readings.csv', df, delimiter=',')\n",
    "    np.savetxt(outTrainPath+'mags.csv', mags, delimiter=',')\n",
    "    np.savetxt(outTrainPath+'angs.csv', angs, delimiter=',')\n",
    "    np.savetxt(outTrainPath+'angsrad.csv', angs*math.pi/180.0, delimiter=',')\n",
    "\n",
    "    np.savetxt(outTestPath+'readings.csv', dfT, delimiter=',')\n",
    "    np.savetxt(outTestPath+'mags.csv', magsT, delimiter=',')\n",
    "    np.savetxt(outTestPath+'angs.csv', angsT, delimiter=',')\n",
    "    np.savetxt(outTestPath+'angsrad.csv', angsT*math.pi/180.0, delimiter=',')\n",
    "\n",
    "    np.savetxt(outValPath+'readings.csv', dfV, delimiter=',')\n",
    "    np.savetxt(outValPath+'mags.csv', magsV, delimiter=',')\n",
    "    np.savetxt(outValPath+'angs.csv', angsV, delimiter=',')\n",
    "    np.savetxt(outValPath+'angsrad.csv', angsV*math.pi/180.0, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "124e2622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the (synthetic) triangle data from hexagon data\n",
    "# Copy the angs, mags, angsrad; take every other reading column\n",
    "\n",
    "N = 5\n",
    "\n",
    "geo0 = 'hex/'\n",
    "trainPath = 'compTrain_N'+str(N)+'/'+geo0\n",
    "testPath = 'compTest_N'+str(N)+'/'+geo0\n",
    "valPath = 'compVal_N'+str(N)+'/'+geo0\n",
    "\n",
    "geo = 'tri/'\n",
    "\n",
    "outTrainPath = 'compTrain_N'+str(N)+'/'+geo\n",
    "outTestPath = 'compTest_N'+str(N)+'/'+geo\n",
    "outValPath = 'compVal_N'+str(N)+'/'+geo\n",
    "\n",
    "\n",
    "shutil.copy(trainPath+'angs.csv', outTrainPath+'angs.csv')\n",
    "shutil.copy(testPath+'angs.csv', outTestPath+'angs.csv')\n",
    "shutil.copy(valPath+'angs.csv', outValPath+'angs.csv')\n",
    "\n",
    "shutil.copy(trainPath+'angsrad.csv', outTrainPath+'angsrad.csv')\n",
    "shutil.copy(testPath+'angsrad.csv', outTestPath+'angsrad.csv')\n",
    "shutil.copy(valPath+'angsrad.csv', outValPath+'angsrad.csv')\n",
    "\n",
    "shutil.copy(trainPath+'mags.csv', outTrainPath+'mags.csv')\n",
    "shutil.copy(testPath+'mags.csv', outTestPath+'mags.csv')\n",
    "shutil.copy(valPath+'mags.csv', outValPath+'mags.csv')\n",
    "\n",
    "df0 = (pd.read_csv(trainPath+'readings.csv', header=None)).to_numpy()\n",
    "df = df0[:,np.array([0, 2, 4])]\n",
    "np.savetxt(outTrainPath+'readings.csv', df, delimiter=',')\n",
    "\n",
    "df0 = (pd.read_csv(testPath+'readings.csv', header=None)).to_numpy()\n",
    "df = df0[:,np.array([0, 2, 4])]\n",
    "np.savetxt(outTestPath+'readings.csv', df, delimiter=',')\n",
    "\n",
    "df0 = (pd.read_csv(valPath+'readings.csv', header=None)).to_numpy()\n",
    "df = df0[:,np.array([0, 2, 4])]\n",
    "np.savetxt(outValPath+'readings.csv', df, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "703f8dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'compVal_N5/squ/mags.csv'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make synthetic square data from hexagon data \n",
    "# Idea: use 0 and 3; make 1 and 4 shift by 15 of the 180 slots. \n",
    "### Split into 8 parts of length 90000 (36000)\n",
    "### For each part, shift by 15*500 = 7500 (15*200 = 3000)\n",
    "'''\n",
    "print(180*500)\n",
    "print(180*200)\n",
    "print(15*500)\n",
    "print(15*200)\n",
    "'''\n",
    "\n",
    "N = 5\n",
    "\n",
    "geo0 = 'hex/'\n",
    "trainPath = 'compTrain_N'+str(N)+'/'+geo0\n",
    "testPath = 'compTest_N'+str(N)+'/'+geo0\n",
    "valPath = 'compVal_N'+str(N)+'/'+geo0\n",
    "\n",
    "geo = 'squ/'\n",
    "\n",
    "outTrainPath = 'compTrain_N'+str(N)+'/'+geo\n",
    "outTestPath = 'compTest_N'+str(N)+'/'+geo\n",
    "outValPath = 'compVal_N'+str(N)+'/'+geo\n",
    "\n",
    "df0 = (pd.read_csv(trainPath+'readings.csv', header=None)).to_numpy()\n",
    "df = df0[:,np.array([0, 1, 3, 4])]\n",
    "dfNew1 = np.zeros(df.shape[0])\n",
    "dfNew3 = np.zeros(df.shape[0])\n",
    "for kk in range(8):\n",
    "    tmp1 = np.roll(df[numAng*nTrain*kk:numAng*nTrain*(kk+1),1],-15*nTrain)\n",
    "    tmp3 = np.roll(df[numAng*nTrain*kk:numAng*nTrain*(kk+1),3],-15*nTrain)\n",
    "    dfNew1[numAng*nTrain*kk:numAng*nTrain*(kk+1)] = tmp1\n",
    "    dfNew3[numAng*nTrain*kk:numAng*nTrain*(kk+1)] = tmp3\n",
    "\n",
    "# put in dfNew1 and dfNew3 into df\n",
    "df[:,1] = dfNew1\n",
    "df[:,3] = dfNew3\n",
    "np.savetxt(outTrainPath+'readings.csv', df, delimiter=',')\n",
    "\n",
    "df0 = (pd.read_csv(testPath+'readings.csv', header=None)).to_numpy()\n",
    "df = df0[:,np.array([0, 1, 3, 4])]\n",
    "dfNew1 = np.zeros(df.shape[0])\n",
    "dfNew3 = np.zeros(df.shape[0])\n",
    "for kk in range(8):\n",
    "    tmp1 = np.roll(df[numAng*nTest*kk:numAng*nTest*(kk+1),1],-15*nTest)\n",
    "    tmp3 = np.roll(df[numAng*nTest*kk:numAng*nTest*(kk+1),3],-15*nTest)\n",
    "    dfNew1[numAng*nTest*kk:numAng*nTest*(kk+1)] = tmp1\n",
    "    dfNew3[numAng*nTest*kk:numAng*nTest*(kk+1)] = tmp3\n",
    "\n",
    "# put in dfNew1 and dfNew3 into df\n",
    "df[:,1] = dfNew1\n",
    "df[:,3] = dfNew3\n",
    "np.savetxt(outTestPath+'readings.csv', df, delimiter=',')\n",
    "\n",
    "df0 = (pd.read_csv(valPath+'readings.csv', header=None)).to_numpy()\n",
    "df = df0[:,np.array([0, 1, 3, 4])]\n",
    "dfNew1 = np.zeros(df.shape[0])\n",
    "dfNew3 = np.zeros(df.shape[0])\n",
    "for kk in range(8):\n",
    "    tmp1 = np.roll(df[numAng*nValidate*kk:numAng*nValidate*(kk+1),1],-15*nValidate)\n",
    "    tmp3 = np.roll(df[numAng*nValidate*kk:numAng*nValidate*(kk+1),3],-15*nValidate)\n",
    "    dfNew1[numAng*nValidate*kk:numAng*nValidate*(kk+1)] = tmp1\n",
    "    dfNew3[numAng*nValidate*kk:numAng*nValidate*(kk+1)] = tmp3\n",
    "\n",
    "# put in dfNew1 and dfNew3 into df\n",
    "df[:,1] = dfNew1\n",
    "df[:,3] = dfNew3\n",
    "np.savetxt(outValPath+'readings.csv', df, delimiter=',')\n",
    "\n",
    "shutil.copy(trainPath+'angs.csv', outTrainPath+'angs.csv')\n",
    "shutil.copy(testPath+'angs.csv', outTestPath+'angs.csv')\n",
    "shutil.copy(valPath+'angs.csv', outValPath+'angs.csv')\n",
    "\n",
    "shutil.copy(trainPath+'angsrad.csv', outTrainPath+'angsrad.csv')\n",
    "shutil.copy(testPath+'angsrad.csv', outTestPath+'angsrad.csv')\n",
    "shutil.copy(valPath+'angsrad.csv', outValPath+'angsrad.csv')\n",
    "\n",
    "shutil.copy(trainPath+'mags.csv', outTrainPath+'mags.csv')\n",
    "shutil.copy(testPath+'mags.csv', outTestPath+'mags.csv')\n",
    "shutil.copy(valPath+'mags.csv', outValPath+'mags.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611d09fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
