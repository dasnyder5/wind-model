{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375547a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "print('Make sure to confirm that the following path is the correct working directory')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e345b908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84d9d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Master Import Block (2-Degree Increments) [I of II]\n",
    "\n",
    "Because the data is so large, we assume that at any point, only a single \n",
    "speed's worth of data is available (i.e. 180 files + the relevant 0-speed readings for a single, fixed Hz). \n",
    "This can be toggled by increasing the nVel parameter, but is NOT recommended (i.e., keep nVel = 1). \n",
    "\n",
    "\n",
    "PARAMETERS: \n",
    "\n",
    "startIdx -- int -- in {1, ..., 8}, represents the lowest Hz we are importing; Hz value is 5*startIdx. \n",
    "nVel     -- int -- in {1, ..., 8}, represents how many sequential Hz we are importing\n",
    "\n",
    "nTrain   -- int -- number of training points at EACH velocity and angle to end up with\n",
    "nTest    -- int -- number of testing points at EACH velocity and angle to end up with\n",
    "N        -- int -- number of points to average over PER datum (effective sampling rate is nominal_rate/N)\n",
    "numAng   -- int -- number of angle increments present in the data; should be a divisor of 360\n",
    "numVel   -- int -- number of different Hz total\n",
    "M        -- int -- number of rows of each file to sample (smaller = faster)\n",
    "\n",
    "RESULT: \n",
    "\n",
    "Output (after manually cycling through numVel instances) is equal to numVel files of mags, angs, angsrad, \n",
    "and readings. These are combined in the next block. \n",
    "'''\n",
    "\n",
    "raise ValueError('Do not run if you already have the csv data!')\n",
    "\n",
    "raise ValueError('Make sure to confirm file path at bottom of this block!')\n",
    "\n",
    "#\n",
    "# BEGIN Parameters to alter by the user\n",
    "#\n",
    "\n",
    "dataPath = 'Data/'\n",
    "trainPath = 'fooTrain/'\n",
    "testPath = 'fooTest/'\n",
    "\n",
    "# Designed to be iterable by simply changing startIdx with everything else fixed\n",
    "\n",
    "startIdx = 1\n",
    "nVel = 1\n",
    "\n",
    "nTrain = 100\n",
    "nTest = 20\n",
    "N = 6\n",
    "numAng = 180       # For 10-degree increments set this to 36 instead of 180\n",
    "numVel = 8\n",
    "M = 4000 \n",
    "#\n",
    "# END Parameters to alter by the user\n",
    "#\n",
    "\n",
    "#\n",
    "# BEGIN derived parameters\n",
    "# \n",
    "numTrain = nTrain*N    # End up with nTrain train points which represent averages over N consecutive samples\n",
    "numTest = nTest*N      # End up with nTest test points which represent averages over N consecutive samples\n",
    "\n",
    "kAng = int(360/numAng)\n",
    "kVel = int(40/numVel)\n",
    "\n",
    "RTL = M - numTrain - numTest - 500\n",
    "RTH = RTL + numTest\n",
    "RL = RTH + 400\n",
    "RH = RL + numTrain\n",
    "\n",
    "if RH > M:\n",
    "    # Error checking. We want to min M (faster read-in, less wasteful), but also need to sample and \n",
    "    # leave some offset between train and test to prevent overfitting to temporal correlations\n",
    "    raise ValueError('RH larger than max_rows (M)! Need to increase M or reduce {N, nTrain, nTest}')\n",
    "\n",
    "# \n",
    "# END derived parameters \n",
    "# \n",
    "\n",
    "#\n",
    "# BEGIN storage arrays to be written out at the end\n",
    "# \n",
    "df = np.zeros((numAng*nVel*nTrain, 6))\n",
    "dfT = np.zeros((numAng*nVel*nTest, 6))\n",
    "mags = np.zeros(numAng*nVel*nTrain)\n",
    "angs = np.zeros(numAng*nVel*nTrain)\n",
    "magsT = np.zeros(numAng*nVel*nTest)\n",
    "angsT = np.zeros(numAng*nVel*nTest)\n",
    "\n",
    "tmpf = np.zeros((nTrain, 6))\n",
    "tmpft = np.zeros((nTest, 6))\n",
    "#\n",
    "# END storage arrays to be written out at the end\n",
    "# \n",
    "\n",
    "# Import the zero-speed data as to difference from the data with velocity\n",
    "txtString2 = dataPath+'calibData_angle_0_samples_30000_frequency_1000_motor_0_Hz.txt'\n",
    "df1 = np.loadtxt(txtString2, skiprows=1, max_rows=M, delimiter=',')\n",
    "\n",
    "# Iterate over the set of velocities (startIdx to startIdx + nVel)\n",
    "for hz in range(startIdx, startIdx+nVel):\n",
    "    # Keep tabs on progress by printing hz value\n",
    "    print(hz)\n",
    "    print()\n",
    "    # Iterate over the set of angles (numAng)\n",
    "    # Assumed to be saved in even degree intervals (e.g. 10 degrees, 2 degrees, etc)\n",
    "    for ang in range(numAng): \n",
    "        # Load the data and difference with zero-velocity readings\n",
    "        txtString = dataPath+'calibData_angle_' + str(int(ang*kAng)) + '_samples_30000_frequency_1000_motor_'+str(int(hz*kVel))+'_Hz.txt'\n",
    "        df0 = np.loadtxt(txtString, skiprows=1, max_rows=M, delimiter=',')\n",
    "        \n",
    "        # Pick out training and test data segments\n",
    "        tmpf0 = (df0[RL:RH,:6] - df1[RL:RH,:6])\n",
    "        tmpft0 = (df0[RTL:RTH,:6] - df1[RTL:RTH,:6])\n",
    "        \n",
    "        # Perform the filtering (averaging), condensing from {numTrain, numTest} to {nTrain, nTest}\n",
    "        for k in range(nTrain):\n",
    "            tmpf[k,:] = np.mean(tmpf0[N*k:N*(k+1),:], axis=0)\n",
    "            if k < nTest:\n",
    "                tmpft[k,:] = np.mean(tmpft0[N*k:N*(k+1),:], axis=0)\n",
    "        \n",
    "        # Put the (nTrain, 6), (nTest, 6) arrays into the larger df, dfT arrays in the right spot\n",
    "        # This represents the train/test features (X)\n",
    "        df[(numAng*nTrain*(hz-startIdx)+ang*nTrain):(numAng*nTrain*(hz-startIdx)+(ang+1)*nTrain),:6] = tmpf\n",
    "        dfT[(numAng*nTest*(hz-startIdx)+ang*nTest):(numAng*nTest*(hz-startIdx)+(ang+1)*nTest),:6] = tmpft\n",
    "        \n",
    "        # Put the (ntrain, ) (nTest, ) arrays into the larger angs, mags, angsT, magsT in the right spot\n",
    "        # This represents the train/test labels (y)\n",
    "        angs[(numAng*nTrain*(hz-startIdx)+ang*nTrain):(numAng*nTrain*(hz-startIdx)+(ang+1)*nTrain)] = ang*kAng*np.ones(nTrain) # Angles in degrees\n",
    "        mags[(numAng*nTrain*(hz-startIdx)+ang*nTrain):(numAng*nTrain*(hz-startIdx)+(ang+1)*nTrain)] = speeds[hz]*np.ones(nTrain)\n",
    "        angsT[(numAng*nTest*(hz-startIdx)+ang*nTest):(numAng*nTest*(hz-startIdx)+(ang+1)*nTest)] = ang*kAng*np.ones(nTest) # Angles in degrees\n",
    "        magsT[(numAng*nTest*(hz-startIdx)+ang*nTest):(numAng*nTest*(hz-startIdx)+(ang+1)*nTest)] = speeds[hz]*np.ones(nTest)\n",
    "        \n",
    "\n",
    "\n",
    "'''\n",
    "Once we have finished, write the results to files\n",
    "This allows us to index files by the idx of the run\n",
    "Here, we assume nVel = 1\n",
    "'''\n",
    "\n",
    "np.savetxt(trainPath+'readings'+str(startIdx)+'.csv', df, delimiter=',')\n",
    "np.savetxt(trainPath+'mags'+str(startIdx)+'.csv', mags, delimiter=',')\n",
    "np.savetxt(trainPath+'angs'+str(startIdx)+'.csv', angs, delimiter=',')\n",
    "\n",
    "np.savetxt(testPath+'readings'+str(startIdx)+'.csv', dfT, delimiter=',')\n",
    "np.savetxt(testPath+'mags'+str(startIdx)+'.csv', magsT, delimiter=',')\n",
    "np.savetxt(testPath+'angs'+str(startIdx)+'.csv', angsT, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a2ad385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nMaster Import Block (2-Degree Increments) [II of II]\\n\\nBecause the data is so large, we assume that at any point, only a single \\nspeed's worth of data is available (i.e. 180 files + the relevant 0-speed readings for a single, fixed Hz). \\nThis can be toggled by increasing the nVel parameter, but is NOT recommended (i.e., keep nVel = 1). \\n\\n\\nINPUT: \\n\\nnumVel files each of mags, angs, angsrad, and readings, named with iterated numbers from 1 to numVel. \\n\\nOUTPUT: \\n\\nA single concatenated file for each of mags, angs, angsrad, and readings, which preserves proper labeling. \\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Master Import Block (2-Degree Increments) [II of II]\n",
    "\n",
    "Because the data is so large, we assume that at any point, only a single \n",
    "speed's worth of data is available (i.e. 180 files + the relevant 0-speed readings for a single, fixed Hz). \n",
    "This can be toggled by increasing the nVel parameter, but is NOT recommended (i.e., keep nVel = 1). \n",
    "\n",
    "\n",
    "INPUT: \n",
    "\n",
    "numVel files each of mags, angs, angsrad, and readings, named with iterated numbers from 1 to numVel. \n",
    "\n",
    "REQUIREMENTS: \n",
    "\n",
    "Parameters from Master Block I in the workspace, specifically: \n",
    "\n",
    "     nTrain\n",
    "     nTest\n",
    "     numAng\n",
    "     numVel\n",
    "\n",
    "OUTPUT: \n",
    "\n",
    "A single concatenated file for each of mags, angs, angsrad, and readings, which preserves proper labeling. \n",
    "'''\n",
    "\n",
    "raise ValueError('Confirm that you actually need to run this function!')\n",
    "\n",
    "raise ValueError('Check the path of the written files, below!')\n",
    "\n",
    "trainPath = 'fooTrain/'\n",
    "testPath = 'fooTest/'\n",
    "\n",
    "df = np.zeros((numAng*numVel*nTrain, 6))\n",
    "dfT = np.zeros((numAng*numVel*nTest, 6))\n",
    "mags = np.zeros(numAng*numVel*nTrain)\n",
    "magsT = np.zeros(numAng*numVel*nTest)\n",
    "angs = np.zeros(numAng*numVel*nTrain)\n",
    "angsT = np.zeros(numAng*numVel*nTest)\n",
    "\n",
    "for k in range(1, 1+numVel):\n",
    "    print(k)\n",
    "    df[numAng*nTrain*(k-1):numAng*nTrain*k,:] = (pd.read_csv(trainPath+'readings'+str(k)+'.csv', header=None)).to_numpy()\n",
    "    mags[numAng*nTrain*(k-1):numAng*nTrain*k] = (pd.read_csv(trainPath+'mags'+str(k)+'.csv', header=None)).to_numpy()[:,0]\n",
    "    angs[numAng*nTrain*(k-1):numAng*nTrain*k] = (pd.read_csv(trainPath+'angs'+str(k)+'.csv', header=None)).to_numpy()[:,0]\n",
    "    \n",
    "    dfT[numAng*nTest*(k-1):numAng*nTest*k,:] = (pd.read_csv(testPath+'readings'+str(k)+'.csv', header=None)).to_numpy()\n",
    "    magsT[numAng*nTest*(k-1):numAng*nTest*k] = (pd.read_csv(testPath+'mags'+str(k)+'.csv', header=None)).to_numpy()[:,0]\n",
    "    angsT[numAng*nTest*(k-1):numAng*nTest*k] = (pd.read_csv(testPath+'angs'+str(k)+'.csv', header=None)).to_numpy()[:,0]\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "# Save the files in the desired format. \n",
    "# The old files loaded above can be kept or manually removed\n",
    "\n",
    "np.savetxt(trainPath+'readings.csv', df, delimiter=',')\n",
    "np.savetxt(trainPath+'mags.csv', mags, delimiter=',')\n",
    "np.savetxt(trainPath+'angs.csv', angs, delimiter=',')\n",
    "np.savetxt(trainPath+'angsrad.csv', angs*math.pi/180.0, delimiter=',')\n",
    "\n",
    "np.savetxt(testPath+'readings.csv', dfT, delimiter=',')\n",
    "np.savetxt(testPath+'mags.csv', magsT, delimiter=',')\n",
    "np.savetxt(testPath+'angs.csv', angsT, delimiter=',')\n",
    "np.savetxt(testPath+'angsrad.csv', angsT*math.pi/180.0, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5201dc6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
