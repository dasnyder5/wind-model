{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from ttictoc import tic, toc\n",
    "\n",
    "print('Make sure to confirm that the following path is the correct working directory')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define speeds (m/s) corresponding to 0-40 Hz settings in wind tunnel\n",
    "### (Just for record-keeping)\n",
    "hzArray = np.array((0, 5, 10, 15, 20, 25, 30, 35, 40))\n",
    "speeds = np.array((0.00, 1.26363735, 1.58562983, 2.07066356, 2.571993, 3.18291372, 3.75322345, 4.33626595, 4.91413509))\n",
    "###\n",
    "\n",
    "#randMat = np.random.rand(600).reshape(-1,6)\n",
    "#print(randMat)\n",
    "#print()\n",
    "#print(np.std(randMat,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Master Import Block (2-Degree Increments) [I of II]\n",
    "\n",
    "Because the data is so large, we assume that at any point, only a single \n",
    "speed's worth of data is available (i.e. 180 files + the relevant 0-speed readings for a single, fixed Hz). \n",
    "This can be toggled by increasing the nVel parameter, but is NOT recommended (i.e., keep nVel = 1). \n",
    "\n",
    "\n",
    "PARAMETERS: \n",
    "\n",
    "startIdx -- int -- in {1, ..., 8}, represents the lowest Hz we are importing; Hz value is 5*startIdx. \n",
    "nVel     -- int -- in {1, ..., 8}, represents how many sequential Hz we are importing\n",
    "\n",
    "nTrain   -- int -- number of training points at EACH velocity and angle to end up with\n",
    "nTest    -- int -- number of testing points at EACH velocity and angle to end up with\n",
    "N        -- int -- number of points to average over PER datum (effective sampling rate is nominal_rate/N)\n",
    "numAng   -- int -- number of angle increments present in the data; should be a divisor of 360\n",
    "numVel   -- int -- number of different Hz total\n",
    "M        -- int -- number of rows of each file to sample (smaller = faster)\n",
    "\n",
    "[TODO]: add a moving-average filter as a possible modification to the data input reading / filtering problem.\n",
    "\n",
    "\n",
    "RESULT: \n",
    "\n",
    "Output (after manually cycling through numVel instances) is equal to numVel files of mags, angs, angsrad, \n",
    "and readings. These are combined in the next block. \n",
    "'''\n",
    "print('To confirm that you wish to continue and possibly overwrite data, type \"c\" to continue:')\n",
    "breakpoint()\n",
    "\n",
    "tic()\n",
    "#\n",
    "# BEGIN Parameters to alter by the user\n",
    "#\n",
    "\n",
    "# Designed to be iterable by simply changing startIdx with everything else fixed\n",
    "startIdx = 1\n",
    "nVel = 8\n",
    "numVel = nVel\n",
    "\n",
    "# Choose geometries (nKeep: hexagon = 6, pentagon = 5, square = 4, triangle = 3...)\n",
    "nInputs = 6\n",
    "KeepArray = np.array((5, 6))\n",
    "\n",
    "nTrain = 500\n",
    "nValidate = 200\n",
    "nTest = 200\n",
    "nArray = np.array((1, 2, 5))              # Number of points to average over\n",
    "deltaN = 20         # How many to skip per sample --> Must be AT LEAST as big as N!\n",
    "numAng = 180        # For 10-degree increments set this to 36 instead of 180\n",
    "\n",
    "#\n",
    "# END Parameters to alter by the user\n",
    "#\n",
    "\n",
    "#\n",
    "# BEGIN derived parameters\n",
    "# \n",
    "oneGo = (startIdx==1 and nVel==8)\n",
    "\n",
    "numTrain = nTrain*(deltaN+1)         # End up with nTrain train points which represent averages over N consecutive samples\n",
    "numValidate = nValidate*(deltaN+1)   # End up with nValidate validation points (each averages over N consecutive samples)\n",
    "numTest = nTest*(deltaN+1)           # End up with nTest test points which represent averages over N consecutive samples\n",
    "\n",
    "M = 6000 + numTrain + numValidate + numTest\n",
    "\n",
    "kAng = int(360/numAng)\n",
    "kVel = int(40/numVel)\n",
    "\n",
    "# \n",
    "# END derived parameters \n",
    "# \n",
    "\n",
    "# FULL LOOP: \n",
    "'''\n",
    "Runs the data processing for each filter length (N in {1, 2, 5}) and geometry (pent/hex). \n",
    "'''\n",
    "for ii in range(len(nArray)):\n",
    "    N = nArray[ii]\n",
    "    np.random.seed(12345*N)\n",
    "    for jj in range(len(KeepArray)):\n",
    "        nKeep = KeepArray[jj]\n",
    "        \n",
    "        # Sort out input data path (dataPath) and output path (geo)\n",
    "        if nKeep == 6:\n",
    "            dataPath = 'data_hex/'\n",
    "            geo = 'hex/' \n",
    "        elif nKeep == 5:\n",
    "            dataPath = 'data_pent/'\n",
    "            geo = 'pent/'\n",
    "        else:\n",
    "            raise ValueError('Unsupported nKeep as of July 2022 - must be either 5 or 6')\n",
    "\n",
    "        # Sort out remaining output paths\n",
    "        if oneGo:\n",
    "            outTrainPath = 'train_N'+str(N)+'/'+geo\n",
    "            outTestPath = 'test_N'+str(N)+'/'+geo\n",
    "            outValPath = 'val_N'+str(N)+'/'+geo\n",
    "        else:\n",
    "            trainPath = 'fooTrain/N'+str(N)+'/'\n",
    "            testPath = 'fooTest/N'+str(N)+'/'\n",
    "            valPath = 'fooVal/N'+str(N)+'/'\n",
    "        \n",
    "        # Sort out file reading and data assimilation\n",
    "        skip1 = 1000 + int(np.floor(np.random.rand()*800))\n",
    "        skip2 = 1000 + int(np.floor(np.random.rand()*800))\n",
    "        \n",
    "        RTL = M - numTrain - numValidate - numTest - 4000\n",
    "        RTH = RTL + numTest\n",
    "        RL0 = RTH + skip1\n",
    "        RH0 = RL0 + numValidate\n",
    "        RL = RH0 + skip2\n",
    "        RH = RL + numTrain\n",
    "        \n",
    "        if RH > M:\n",
    "            # Error checking. We want to min M (faster read-in, less wasteful), but also need to sample and \n",
    "            # leave some offset between train and test to prevent overfitting to temporal correlations\n",
    "            raise ValueError('RH larger than max_rows (M)! Need to increase M or reduce {N, nTrain, nTest}')\n",
    "\n",
    "        #\n",
    "        # BEGIN storage arrays to be written out at the end\n",
    "        # \n",
    "        df = np.zeros(((numAng*nVel+1)*nTrain, nKeep))\n",
    "        dfT = np.zeros(((numAng*nVel+1)*nTest, nKeep))\n",
    "        dfV = np.zeros(((numAng*nVel+1)*nValidate, nKeep))\n",
    "        mags = np.zeros((numAng*nVel+1)*nTrain)\n",
    "        angs = np.zeros((numAng*nVel+1)*nTrain)\n",
    "        magsT = np.zeros((numAng*nVel+1)*nTest)\n",
    "        angsT = np.zeros((numAng*nVel+1)*nTest)\n",
    "        magsV = np.zeros((numAng*nVel+1)*nValidate)\n",
    "        angsV = np.zeros((numAng*nVel+1)*nValidate)\n",
    "\n",
    "\n",
    "        tmpf = np.zeros((nTrain, nKeep))\n",
    "        tmpft = np.zeros((nTest, nKeep))\n",
    "        tmpfv = np.zeros((nValidate, nKeep))\n",
    "        #\n",
    "        # END storage arrays to be written out at the end\n",
    "        # \n",
    "\n",
    "        # Iterate over the set of velocities (startIdx to startIdx + nVel)\n",
    "        for hz in range(startIdx, startIdx+nVel):\n",
    "            if nKeep == 6:\n",
    "                zeroDataStr = 'calibData'+str(hz)+'_angle_0_samples_30000_frequency_1000_motor_0_Hz.txt'\n",
    "            else: \n",
    "                zeroDataStr = 'zeros'+str(hz)+'_angle_0_samples_30000_frequency_1000_motor_0_Hz.txt'\n",
    "\n",
    "            txtString2 = dataPath+zeroDataStr\n",
    "            df1 = np.loadtxt(txtString2, skiprows=1, max_rows=M, delimiter=',')\n",
    "\n",
    "            # Extract means from the zeroed-out data for each sensor. Mean of Nx7 array to 1x7\n",
    "            df1avg = np.mean(df1, axis=0)\n",
    "\n",
    "            # Iterate over the set of angles (numAng)\n",
    "            # Assumed to be saved in even degree intervals (e.g. 10 degrees, 2 degrees, etc)\n",
    "            for ang in range(numAng): \n",
    "                '''\n",
    "                Load the data and difference with zero-velocity means\n",
    "                For Hexagon:\n",
    "                  -- txtString = dataPath+'calibData_angle_' + str(int(ang*kAng)) + '_samples_30000_frequency_1000_motor_'+str(int(hz*kVel))+'_Hz.txt'\n",
    "                For Pentagon: \n",
    "                  -- txtString = dataPath+'data_degInc_2_angle_' + str(int(ang*kAng)) + '_samples_30000_frequency_1000_motor_'+str(int(hz*kVel))+'_Hz.txt'\n",
    "                '''\n",
    "                if nKeep == 5:\n",
    "                    txtString = dataPath+'data_degInc_2_angle_' + str(int(ang*kAng)) + '_samples_30000_frequency_1000_motor_'+str(int(hz*kVel))+'_Hz.txt'\n",
    "                elif nKeep == 6:\n",
    "                    txtString = dataPath+'calibData_angle_' + str(int(ang*kAng)) + '_samples_30000_frequency_1000_motor_'+str(int(hz*kVel))+'_Hz.txt'\n",
    "                else: \n",
    "                    raise ValueError('Unsupported nKeep as of June 27 2022 - must be 5 or 6')\n",
    "\n",
    "                df0 = np.loadtxt(txtString, skiprows=1, max_rows=M, delimiter=',')\n",
    "\n",
    "                # Pick out training, validation, and test data segments\n",
    "                tmpf0 = (df0[RL:RH,:nKeep] - df1avg[:nKeep]) # df1[RL:RH,:nKeep])\n",
    "                tmpft0 = (df0[RTL:RTH,:nKeep] - df1avg[:nKeep]) # df1[RTL:RTH,:nKeep])\n",
    "                tmpfv0 = (df0[RL0:RH0,:nKeep] - df1avg[:nKeep]) # df1[RL0:RH0,:nKeep])\n",
    "\n",
    "                # Perform the filtering (averaging), condensing from {numTrain, numTest} to {nTrain, nTest}\n",
    "                for k in range(nTrain):\n",
    "                    tmpf[k,:] = np.mean(tmpf0[deltaN*k:deltaN*k+N,:], axis=0)\n",
    "                    if k < nTest:\n",
    "                        tmpft[k,:] = np.mean(tmpft0[deltaN*k:deltaN*k+N,:], axis=0)\n",
    "                    if k < nValidate:\n",
    "                        tmpfv[k,:] = np.mean(tmpfv0[deltaN*k:deltaN*k+N,:], axis=0)\n",
    "\n",
    "                # Put the (nTrain, nKeep), (nVal, nKeep), (nTest, nKeep) arrays into the larger df, dfV, dfT arrays in the right spot\n",
    "                # This represents the train/val/test features (X)\n",
    "                df[(numAng*nTrain*(hz-startIdx)+ang*nTrain):(numAng*nTrain*(hz-startIdx)+(ang+1)*nTrain),:nKeep] = tmpf\n",
    "                dfT[(numAng*nTest*(hz-startIdx)+ang*nTest):(numAng*nTest*(hz-startIdx)+(ang+1)*nTest),:nKeep] = tmpft\n",
    "                dfV[(numAng*nValidate*(hz-startIdx)+ang*nValidate):(numAng*nValidate*(hz-startIdx)+(ang+1)*nValidate),:nKeep] = tmpfv\n",
    "\n",
    "                # Put the (nTrain, ), (nVal, ), (nTest, ) arrays into the larger angs, mags, angsT, magsT in the right spot\n",
    "                # This represents the train/val/test labels (y)\n",
    "                angs[(numAng*nTrain*(hz-startIdx)+ang*nTrain):(numAng*nTrain*(hz-startIdx)+(ang+1)*nTrain)] = ang*kAng*np.ones(nTrain) # Angles in degrees\n",
    "                mags[(numAng*nTrain*(hz-startIdx)+ang*nTrain):(numAng*nTrain*(hz-startIdx)+(ang+1)*nTrain)] = speeds[hz]*np.ones(nTrain) # Speeds in m/s\n",
    "                angsT[(numAng*nTest*(hz-startIdx)+ang*nTest):(numAng*nTest*(hz-startIdx)+(ang+1)*nTest)] = ang*kAng*np.ones(nTest) # Angles in degrees\n",
    "                magsT[(numAng*nTest*(hz-startIdx)+ang*nTest):(numAng*nTest*(hz-startIdx)+(ang+1)*nTest)] = speeds[hz]*np.ones(nTest) # Speeds in m/s\n",
    "                angsV[(numAng*nValidate*(hz-startIdx)+ang*nValidate):(numAng*nValidate*(hz-startIdx)+(ang+1)*nValidate)] = ang*kAng*np.ones(nValidate) # Angles in degrees\n",
    "                magsV[(numAng*nValidate*(hz-startIdx)+ang*nValidate):(numAng*nValidate*(hz-startIdx)+(ang+1)*nValidate)] = speeds[hz]*np.ones(nValidate) # Speeds in m/s\n",
    "\n",
    "        # \n",
    "        # Generate synthetic data at zero velocity with std similar to other readings, and append to training\n",
    "        # Note that labels default to zero (and angle wlog is zero), so only need to update readings.csv arrays\n",
    "        #\n",
    "        zero_stds = np.zeros((nVel, nKeep))\n",
    "        for hz in range(startIdx, startIdx+nVel):\n",
    "            # Import the zero-speed data as to difference from the data with velocity\n",
    "            if nKeep == 5:\n",
    "                zeroDataStr = 'zeros'+str(hz)+'_angle_0_samples_30000_frequency_1000_motor_0_Hz.txt'\n",
    "            else: \n",
    "                zeroDataStr = 'calibData'+str(hz)+'_angle_0_samples_30000_frequency_1000_motor_0_Hz.txt'\n",
    "\n",
    "            # For hexagon: 'calibData_angle_0_samples_30000_frequency_1000_motor_0_Hz.txt'\n",
    "            # For pentagon: 'zeros'+str(hz)+'_angle_0_samples_30000_frequency_1000_motor_0_Hz.txt'\n",
    "\n",
    "            txtString2 = dataPath+zeroDataStr\n",
    "            df1 = np.loadtxt(txtString2, skiprows=1, delimiter=',')\n",
    "            zero_stds[hz-1,:] = np.std(df1, axis=0)[:nKeep]\n",
    "\n",
    "        sigma0 = np.mean(zero_stds, axis=0)\n",
    "        for jj in range(nKeep):\n",
    "            tmpf[:,jj] = np.random.normal(0.0, sigma0[jj], nTrain)\n",
    "            tmpft[:,jj] = np.random.normal(0.0, sigma0[jj], nTest)\n",
    "            tmpfv[:,jj] = np.random.normal(0.0, sigma0[jj], nValidate)\n",
    "\n",
    "        df[-nTrain:,:nKeep] = tmpf\n",
    "        dfT[-nTest:,:nKeep] = tmpft\n",
    "        dfV[-nValidate:,:nKeep] = tmpfv      \n",
    "\n",
    "\n",
    "        # \n",
    "        # \n",
    "        #\n",
    "        '''\n",
    "        Once we have finished, write the results to files\n",
    "        This allows us to index files by the idx of the run\n",
    "        Here, we assume nVel = 1\n",
    "        '''\n",
    "        if oneGo:\n",
    "            np.savetxt(outTrainPath+'readings.csv', df, delimiter=',')\n",
    "            np.savetxt(outTrainPath+'mags.csv', mags, delimiter=',')\n",
    "            np.savetxt(outTrainPath+'angs.csv', angs, delimiter=',')\n",
    "            np.savetxt(outTrainPath+'angsrad.csv', angs*math.pi/180.0, delimiter=',')\n",
    "\n",
    "            np.savetxt(outTestPath+'readings.csv', dfT, delimiter=',')\n",
    "            np.savetxt(outTestPath+'mags.csv', magsT, delimiter=',')\n",
    "            np.savetxt(outTestPath+'angs.csv', angsT, delimiter=',')\n",
    "            np.savetxt(outTestPath+'angsrad.csv', angsT*math.pi/180.0, delimiter=',')\n",
    "\n",
    "            np.savetxt(outValPath+'readings.csv', dfV, delimiter=',')\n",
    "            np.savetxt(outValPath+'mags.csv', magsV, delimiter=',')\n",
    "            np.savetxt(outValPath+'angs.csv', angsV, delimiter=',')\n",
    "            np.savetxt(outValPath+'angsrad.csv', angsV*math.pi/180.0, delimiter=',')\n",
    "\n",
    "        else:\n",
    "            np.savetxt(trainPath+'readings'+str(startIdx)+'.csv', df, delimiter=',')\n",
    "            np.savetxt(trainPath+'mags'+str(startIdx)+'.csv', mags, delimiter=',')\n",
    "            np.savetxt(trainPath+'angs'+str(startIdx)+'.csv', angs, delimiter=',')\n",
    "\n",
    "            np.savetxt(testPath+'readings'+str(startIdx)+'.csv', dfT, delimiter=',')\n",
    "            np.savetxt(testPath+'mags'+str(startIdx)+'.csv', magsT, delimiter=',')\n",
    "            np.savetxt(testPath+'angs'+str(startIdx)+'.csv', angsT, delimiter=',')\n",
    "\n",
    "            np.savetxt(valPath+'readings'+str(startIdx)+'.csv', dfV, delimiter=',')\n",
    "            np.savetxt(valPath+'mags'+str(startIdx)+'.csv', magsV, delimiter=',')\n",
    "            np.savetxt(valPath+'angs'+str(startIdx)+'.csv', angsV, delimiter=',')\n",
    "\n",
    "\n",
    "# Keep track of the total time taken to process\n",
    "# Round out to hrs // minutes // seconds\n",
    "dT = toc()\n",
    "dT = np.round_(dT)\n",
    "dT2 = dT % 3600\n",
    "dT3 = dT2 % 60\n",
    "print(f\"Elapsed time is {dT} seconds\")\n",
    "print(f\"This is equivalent to {dT // 3600} hours, \"+f\"{dT2 // 60} minutes, and \"+f\"{dT3} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the (synthetic) triangle data from hexagon data\n",
    "# Copy the angs, mags, angsrad; take every other reading column\n",
    "\n",
    "nArray = np.array((1, 2, 5))\n",
    "geo0 = 'hex/'\n",
    "geo = 'tri/'\n",
    "\n",
    "for ii in range(len(nArray)):\n",
    "    N = nArray[ii]\n",
    "    \n",
    "    inTrainPath = 'train_N'+str(N)+'/'+geo0\n",
    "    inTestPath = 'test_N'+str(N)+'/'+geo0\n",
    "    inValPath = 'val_N'+str(N)+'/'+geo0\n",
    "\n",
    "    outTrainPath = 'train_N'+str(N)+'/'+geo\n",
    "    outTestPath = 'test_N'+str(N)+'/'+geo\n",
    "    outValPath = 'val_N'+str(N)+'/'+geo\n",
    "\n",
    "    shutil.copy(inTrainPath+'angs.csv', outTrainPath+'angs.csv')\n",
    "    shutil.copy(inTestPath+'angs.csv', outTestPath+'angs.csv')\n",
    "    shutil.copy(inValPath+'angs.csv', outValPath+'angs.csv')\n",
    "\n",
    "    shutil.copy(inTrainPath+'angsrad.csv', outTrainPath+'angsrad.csv')\n",
    "    shutil.copy(inTestPath+'angsrad.csv', outTestPath+'angsrad.csv')\n",
    "    shutil.copy(inValPath+'angsrad.csv', outValPath+'angsrad.csv')\n",
    "\n",
    "    shutil.copy(inTrainPath+'mags.csv', outTrainPath+'mags.csv')\n",
    "    shutil.copy(inTestPath+'mags.csv', outTestPath+'mags.csv')\n",
    "    shutil.copy(inValPath+'mags.csv', outValPath+'mags.csv')\n",
    "\n",
    "    df0 = (pd.read_csv(inTrainPath+'readings.csv', header=None)).to_numpy()\n",
    "    df = df0[:,np.array([0, 2, 4])]\n",
    "    np.savetxt(outTrainPath+'readings.csv', df, delimiter=',')\n",
    "\n",
    "    df0 = (pd.read_csv(inTestPath+'readings.csv', header=None)).to_numpy()\n",
    "    df = df0[:,np.array([0, 2, 4])]\n",
    "    np.savetxt(outTestPath+'readings.csv', df, delimiter=',')\n",
    "\n",
    "    df0 = (pd.read_csv(inValPath+'readings.csv', header=None)).to_numpy()\n",
    "    df = df0[:,np.array([0, 2, 4])]\n",
    "    np.savetxt(outValPath+'readings.csv', df, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make synthetic square data from hexagon data \n",
    "# Idea: use 0 and 3; make 1 and 4 shift by 15 of the 180 slots. \n",
    "### Split into 8 parts of length 90000 (36000)\n",
    "### For each part, shift by 15*500 = 7500 (15*200 = 3000)\n",
    "'''\n",
    "print(180*500)\n",
    "print(180*200)\n",
    "print(15*500)\n",
    "print(15*200)\n",
    "'''\n",
    "\n",
    "nArray = np.array((1, 2, 5))\n",
    "geo0 = 'hex/'\n",
    "geo = 'squ/'\n",
    "\n",
    "for ii in range(len(nArray)):\n",
    "    N = nArray[ii]\n",
    "\n",
    "    trainPath = 'train_N'+str(N)+'/'+geo0\n",
    "    testPath = 'test_N'+str(N)+'/'+geo0\n",
    "    valPath = 'val_N'+str(N)+'/'+geo0\n",
    "\n",
    "    outTrainPath = 'train_N'+str(N)+'/'+geo\n",
    "    outTestPath = 'test_N'+str(N)+'/'+geo\n",
    "    outValPath = 'val_N'+str(N)+'/'+geo\n",
    "\n",
    "    df0 = (pd.read_csv(trainPath+'readings.csv', header=None)).to_numpy()\n",
    "    df = df0[:,np.array([0, 1, 3, 4])]\n",
    "    dfNew1 = np.zeros(df.shape[0])\n",
    "    dfNew3 = np.zeros(df.shape[0])\n",
    "    for kk in range(8):\n",
    "        tmp1 = np.roll(df[numAng*nTrain*kk:numAng*nTrain*(kk+1),1],-15*nTrain)\n",
    "        tmp3 = np.roll(df[numAng*nTrain*kk:numAng*nTrain*(kk+1),3],-15*nTrain)\n",
    "        dfNew1[numAng*nTrain*kk:numAng*nTrain*(kk+1)] = tmp1\n",
    "        dfNew3[numAng*nTrain*kk:numAng*nTrain*(kk+1)] = tmp3\n",
    "\n",
    "    # put in dfNew1 and dfNew3 into df\n",
    "    df[:,1] = dfNew1\n",
    "    df[:,3] = dfNew3\n",
    "    np.savetxt(outTrainPath+'readings.csv', df, delimiter=',')\n",
    "\n",
    "    df0 = (pd.read_csv(testPath+'readings.csv', header=None)).to_numpy()\n",
    "    df = df0[:,np.array([0, 1, 3, 4])]\n",
    "    dfNew1 = np.zeros(df.shape[0])\n",
    "    dfNew3 = np.zeros(df.shape[0])\n",
    "    for kk in range(8):\n",
    "        tmp1 = np.roll(df[numAng*nTest*kk:numAng*nTest*(kk+1),1],-15*nTest)\n",
    "        tmp3 = np.roll(df[numAng*nTest*kk:numAng*nTest*(kk+1),3],-15*nTest)\n",
    "        dfNew1[numAng*nTest*kk:numAng*nTest*(kk+1)] = tmp1\n",
    "        dfNew3[numAng*nTest*kk:numAng*nTest*(kk+1)] = tmp3\n",
    "\n",
    "    # put in dfNew1 and dfNew3 into df\n",
    "    df[:,1] = dfNew1\n",
    "    df[:,3] = dfNew3\n",
    "    np.savetxt(outTestPath+'readings.csv', df, delimiter=',')\n",
    "\n",
    "    df0 = (pd.read_csv(valPath+'readings.csv', header=None)).to_numpy()\n",
    "    df = df0[:,np.array([0, 1, 3, 4])]\n",
    "    dfNew1 = np.zeros(df.shape[0])\n",
    "    dfNew3 = np.zeros(df.shape[0])\n",
    "    for kk in range(8):\n",
    "        tmp1 = np.roll(df[numAng*nValidate*kk:numAng*nValidate*(kk+1),1],-15*nValidate)\n",
    "        tmp3 = np.roll(df[numAng*nValidate*kk:numAng*nValidate*(kk+1),3],-15*nValidate)\n",
    "        dfNew1[numAng*nValidate*kk:numAng*nValidate*(kk+1)] = tmp1\n",
    "        dfNew3[numAng*nValidate*kk:numAng*nValidate*(kk+1)] = tmp3\n",
    "\n",
    "    # put in dfNew1 and dfNew3 into df\n",
    "    df[:,1] = dfNew1\n",
    "    df[:,3] = dfNew3\n",
    "    np.savetxt(outValPath+'readings.csv', df, delimiter=',')\n",
    "\n",
    "    shutil.copy(trainPath+'angs.csv', outTrainPath+'angs.csv')\n",
    "    shutil.copy(testPath+'angs.csv', outTestPath+'angs.csv')\n",
    "    shutil.copy(valPath+'angs.csv', outValPath+'angs.csv')\n",
    "\n",
    "    shutil.copy(trainPath+'angsrad.csv', outTrainPath+'angsrad.csv')\n",
    "    shutil.copy(testPath+'angsrad.csv', outTestPath+'angsrad.csv')\n",
    "    shutil.copy(valPath+'angsrad.csv', outValPath+'angsrad.csv')\n",
    "\n",
    "    shutil.copy(trainPath+'mags.csv', outTrainPath+'mags.csv')\n",
    "    shutil.copy(testPath+'mags.csv', outTestPath+'mags.csv')\n",
    "    shutil.copy(valPath+'mags.csv', outValPath+'mags.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
