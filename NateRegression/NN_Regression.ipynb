{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc0b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "# Requirements:\n",
    "# (1) pytorch \n",
    "# (2) numpy \n",
    "# (3) matplotlib\n",
    "# (4) pandas\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import csv\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd733fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define speeds (m/s) corresponding to 0-40 Hz settings in wind tunnel\n",
    "### (Just for record-keeping)\n",
    "hzArray = np.array((0, 5, 10, 15, 20, 25, 30, 35, 40))\n",
    "speedArray = np.array((0.00, 1.26363735, 1.58562983, 2.07066356, 2.571993, 3.18291372, 3.75322345, 4.33626595, 4.91413509))\n",
    "###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331d20cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossWireDataset(Dataset):\n",
    "    '''\n",
    "    Dataset class for pytorch-based learning tailored to crosswire model training. This method \n",
    "    essentially is feature learning of a specific, reduced set of features from the sensor readings, \n",
    "    namely: \n",
    "\n",
    "    [Input Features]\n",
    "       --- The maximal (absolute) voltage reading (voltage)\n",
    "       --- The index of the maximal (absolute) voltage reading (integer, {1-6})\n",
    "       --- The (regularized) ratio of the adjacent sensors (voltage/voltage)\n",
    "    [Predictions]\n",
    "       --- The gust speed (m/s)\n",
    "       --- The gust incident angle (radians)\n",
    "\n",
    "    '''\n",
    "    def __init__(self, magFile, angFile, readingsFile, transform=None, target_transform=None):\n",
    "        # Construct the labels\n",
    "        tmpMag = pd.read_csv(magFile)\n",
    "        tmpAng = pd.read_csv(angFile)\n",
    "        self.mags = torch.Tensor(tmpMag.to_numpy())\n",
    "        self.angs = torch.Tensor(tmpAng.to_numpy())\n",
    "        \n",
    "        # Construct the features and place them into readings array(X). \n",
    "        tmpReadings = pd.read_csv(readingsFile)\n",
    "        tmpReadings = tmpReadings.to_numpy()\n",
    "        print(tmpReadings.shape)\n",
    "        LL = tmpReadings.shape[0]\n",
    "        tmpReadings2 = np.zeros((LL, 3))\n",
    "        for k in range(LL):\n",
    "            tmpReadings2[k, 0] = np.max(np.abs(tmpReadings[k, :]))\n",
    "            tmpReadings2[k, 1] = np.argmax(np.abs(tmpReadings[k, :]))\n",
    "            tt = int(tmpReadings2[k,1])\n",
    "            tmpReadings2[k, 2] = np.abs(tmpReadings[k, (tt-1)%6])/(np.abs(tmpReadings[k, (tt+1)%6]) + 0.05)\n",
    "        \n",
    "        self.readings = torch.Tensor(tmpReadings2)\n",
    "        \n",
    "        # Incorporate the transforms as needed\n",
    "        self.transform=transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.mags)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        reading = self.readings[idx, :]\n",
    "        mag = self.mags[idx]\n",
    "        ang = self.angs[idx]\n",
    "        label = torch.cat((mag, ang), 0)\n",
    "        \n",
    "        if self.transform:\n",
    "            reading = self.transform(reading)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return reading, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd318be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindMagDataset(Dataset):\n",
    "    '''\n",
    "    Dataset class for pytorch-based learning for gust magnitude data training. This method \n",
    "    learns directly from the sensor readings (voltages) to predict gust speed (m/s). \n",
    "    [Inputs]\n",
    "       --- The sensor readings (voltages)\n",
    "    [Predictions]\n",
    "       --- The gust speed (m/s)\n",
    "    '''\n",
    "    def __init__(self, magFile, readingsFile, transform=None, target_transform=None):\n",
    "        tmpMag = pd.read_csv(magFile)\n",
    "        tmpReadings = pd.read_csv(readingsFile)\n",
    "        self.mags = torch.Tensor(tmpMag.to_numpy())\n",
    "        self.readings = torch.Tensor(tmpReadings.to_numpy())\n",
    "        \n",
    "        # Incorporate the transforms as needed\n",
    "        self.transform=transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.mags)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        reading = self.readings[idx, :]\n",
    "        label = self.mags[idx]\n",
    "        if self.transform:\n",
    "            reading = self.transform(reading)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return reading, label\n",
    "\n",
    "class WindAngDataset(Dataset):\n",
    "    '''\n",
    "    Dataset class for pytorch-based learning for gust angle data training. This method \n",
    "    learns directly from the sensor readings (voltages) to predict gust incidence angle (radians). \n",
    "    [Inputs]\n",
    "       --- The sensor readings (voltages)\n",
    "    [Predictions]\n",
    "       --- The gust angle (rad)\n",
    "    '''\n",
    "    def __init__(self, angFile, readingsFile, transform=None, target_transform=None):\n",
    "        tmpAng = pd.read_csv(angFile)\n",
    "        tmpReadings = pd.read_csv(readingsFile)\n",
    "        self.angs = torch.Tensor(tmpAng.to_numpy())\n",
    "        self.readings = torch.Tensor(tmpReadings.to_numpy())\n",
    "        \n",
    "        # Incorporate the transforms as needed\n",
    "        self.transform=transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.angs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        reading = self.readings[idx, :]\n",
    "        label = self.angs[idx]\n",
    "        if self.transform:\n",
    "            reading = self.transform(reading)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return reading, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfc723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    '''\n",
    "    A general/generic Neural Network model class for use with Pytorch. \n",
    "    \n",
    "    TODO: include layer widths, types, and nonlinearities as inputs and dynamically allocate\n",
    "          --- this will allow for custom classes rather than the clunky \"if\" statement used here. \n",
    "    '''\n",
    "    def __init__(self, crosswire=False, fullAngles=False, geom=6):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        if crosswire:\n",
    "            # Architecture to use for crosswire prediction\n",
    "            # Input size is 3  --- three crosswire features\n",
    "            # Output size is 2 --- speed (m/s) and angle (rad)\n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(3, 25),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(25, 15),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(15, 2),\n",
    "            )\n",
    "        else:\n",
    "            if fullAngles:\n",
    "                # Architecture to use for angle prediction if the data is dense (2-degree increments)\n",
    "                # Input size is 6  --- six sensor readings (voltages)\n",
    "                # Output size is 1 --- angle (rad)\n",
    "                self.linear_relu_stack = nn.Sequential(\n",
    "                    nn.Linear(geom, 30),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(30, 18),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(18, 1),\n",
    "                )\n",
    "            else:\n",
    "                # Architecture to use for speed prediction (generally) and for angle prediction \n",
    "                # if the data is NOT dense (e.g., is in 10-degree increments)\n",
    "                # Input size is 6  --- six sensor readings (voltages)\n",
    "                # Output size is 1 --- either speed (m/s) or angle (rad)\n",
    "                self.linear_relu_stack = nn.Sequential(\n",
    "                    nn.Linear(geom, 50),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(50, 25),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(25, 1),\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Method to propagate input (reading) through the network to get a prediction. \n",
    "        # Terminology is clunky because this is adapted from a classification example, hence \n",
    "        # the use of 'logits' even though we are doing regression.\n",
    "        \n",
    "        # TODO -- tidy up variable names, usage, etc (see above)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3226a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, optimizer, epochNum, seedNum, loss_fn=nn.L1Loss(), verbose=True, batch_size=180, writePath=None):\n",
    "    \"\"\"\n",
    "    Loop for training a 'model' (class NeuralNetwork) on data stored in 'dataloader,' using loss function\n",
    "    'loss_fn' and optimizer method 'optimizer'\n",
    "    \n",
    "    [Inputs]\n",
    "    dataloader    -- type DataLoader    -- Pytorch DataLoader object to facilitate training/testing data storage\n",
    "                                           to interface with pytorch optimization and training modules\n",
    "                                           \n",
    "    model         -- type NeuralNetwork -- Pytorch NeuralNetwork object to facilitate training/testing of speed and \n",
    "                                           angle prediction for FlowDrone\n",
    "                                           \n",
    "    epochNum      -- type int           -- Current epoch number to track training loss\n",
    "    \n",
    "    seedNum       -- type int           -- Seed of the current run (to average over to demonstrate convergence)\n",
    "    \n",
    "    loss_fn       -- type torch.nn loss -- Pytorch loss function (in nn library) for training the speed/angle predictor\n",
    "                                           for FlowDrone. Defaults to nn.MSELoss() because we are regressing real-valued\n",
    "                                           variables. \n",
    "                                           \n",
    "    optimizer     -- type torch.optim   -- Pytorch optimizer for ANN weight updates. Normally will use ADAM unless there\n",
    "                                           is a compelling reason to deviate. \n",
    "    \n",
    "    verbose       -- type Boolean       -- Toggles printing of training loss during training. Default is TRUE. \n",
    "    \n",
    "    writePath     -- type String        -- If present, a path to write to a csv file in order \n",
    "    [Outputs]\n",
    "    \n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    f = open(writePath+'trainCostInit'+str(seedNum)+'.csv', 'a')\n",
    "    writer = csv.writer(f)\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        for k in range(pred.shape[0]):\n",
    "            if (pred[k, -1] >= 330.0*math.pi/180.0 and y[k, -1] <= 30.0*math.pi/180.0):\n",
    "                pred[k, -1] += -2.0*math.pi\n",
    "            elif (pred[k, -1] <= 30.0*math.pi/180.0 and y[k, -1] >= 330.0*math.pi/180.0):\n",
    "                pred[k, -1] += 2.0*math.pi\n",
    "\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss_average = (torch.sum(loss)/pred.shape[0]).cpu().detach().numpy()\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 200 == 1:\n",
    "            if verbose:\n",
    "                loss, current = loss.item(), batch * len(X)\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "            if writePath is None:\n",
    "                pass\n",
    "            else: \n",
    "                writer.writerow(np.array([(batch + (np.ceil(size/batch_size)*epochNum)), 180.0*loss_average/math.pi]))\n",
    "                \n",
    "\n",
    "    # close the file\n",
    "    f.close()\n",
    "        \n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, epochNum, seedNum, loss_fn=nn.L1Loss(), lastLoop=False, writePath=None):\n",
    "    \"\"\"\n",
    "    Loop for test a 'model' (class NeuralNetwork) on data stored in 'dataloader,' using loss function\n",
    "    'loss_fn.'\n",
    "    \n",
    "    [Inputs]\n",
    "    dataloader    -- type DataLoader    -- Pytorch DataLoader object to facilitate training/testing data storage\n",
    "                                           to interface with pytorch optimization and training modules\n",
    "                                           \n",
    "    model         -- type NeuralNetwork -- Pytorch NeuralNetwork object to facilitate training/testing of speed and \n",
    "                                           angle prediction for FlowDrone\n",
    "\n",
    "    epochNum      -- type Int           -- Current epoch\n",
    "    \n",
    "    loss_fn       -- type torch.nn loss -- Pytorch loss function (in nn library) for training the speed/angle predictor\n",
    "                                           for FlowDrone. Defaults to nn.MSELoss() because we are regressing real-valued\n",
    "                                           variables. \n",
    "                                           \n",
    "    lastLoop      -- type Boolean       -- Whether we are on the last epoch (for histogram information)\n",
    "    \n",
    "    writePath     -- type String        -- File to write to\n",
    "    [Outputs]\n",
    "    \n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    print(num_batches)\n",
    "    hists = False\n",
    "    \n",
    "    if lastLoop:\n",
    "        if (num_batches == size):\n",
    "            errs = np.zeros(size)\n",
    "            idxVal = 0\n",
    "            hists = True\n",
    "        \n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            for k in range(pred.shape[0]):\n",
    "                if (pred[k, -1] >= 330.0*math.pi/180.0 and y[k, -1] <= 30.0*math.pi/180.0):\n",
    "                    pred[k, -1] += -2.0*math.pi\n",
    "                elif (pred[k, -1] <= 30.0*math.pi/180.0 and y[k, -1] >= 330.0*math.pi/180.0):\n",
    "                    pred[k, -1] += 2.0*math.pi\n",
    "                \n",
    "            if hists:\n",
    "                errs[idxVal] = loss_fn(pred, y).item()\n",
    "                test_loss += errs[idxVal]\n",
    "                idxVal += 1\n",
    "            else:\n",
    "                test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Avg loss: {test_loss:>8f} \\n\")\n",
    "    print(f\"Avg error (deg): {(test_loss*180.0/math.pi):>8f} \\n\")\n",
    "    \n",
    "    if writePath is None:\n",
    "        pass\n",
    "    else:\n",
    "        # open the file\n",
    "        f = open(writePath+'testCostInit'+str(seedNum)+'.csv', 'a')\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        # write out the relevant cost\n",
    "        writer.writerow(np.array([epochNum, test_loss*180.0/math.pi]))\n",
    "                \n",
    "        # close the file\n",
    "        f.close()\n",
    "    \n",
    "    if hists:\n",
    "        plt.figure(1)\n",
    "        plt.hist(errs)\n",
    "        plt.show()\n",
    "        \n",
    "        return test_loss, errs\n",
    "    else: \n",
    "        return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bd7488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDataset(dataSetType=2, geometryVal=3, compFlag=True, N=1, epochs0=15):\n",
    "    # Make dataset\n",
    "    # Change this as desired in {1, 2, 3, 4, 5}\n",
    "    #\n",
    "    # INDEX: \n",
    "    #   --- (1) Sparse wind magnitudes                         [OLD]\n",
    "    #   --- (2) Sparse wind angles (10-degree increments)      [OLD]\n",
    "    #   --- (3) Dense Crosswire Model \n",
    "    #   --- (4) Dense Wind Magnitudes \n",
    "    #   --- (5) Dense Incidence Angles (2-degree increments)\n",
    "    \n",
    "    ### dataSetType = 2\n",
    "\n",
    "    # 3=Triangle, 4=Square, 5=Pentagon, 6=Hexagon\n",
    "    ### geometryVal = 3\n",
    "    ### compFlag=True\n",
    "    ### N = 1                 # Number of sequentially averaged data points\n",
    "\n",
    "    if geometryVal == 3:\n",
    "        geomPath='tri/'\n",
    "    elif geometryVal == 4:\n",
    "        geomPath='squ/'\n",
    "    elif geometryVal == 5:\n",
    "        geomPath='pent/'\n",
    "    elif geometryVal == 6:\n",
    "        geomPath='hex/'\n",
    "    else:\n",
    "        raise ValueError('Geometry must be in {3, 4, 5, 6}')\n",
    "\n",
    "    trainLabelPath = 'compTrain/'\n",
    "    testLabelPath = 'compVal/'\n",
    "    trainPath='compTrain_N'+str(N)+'/'\n",
    "    testPath='compVal_N'+str(N)+'/'       # Set to validation data for network/hyperparameter optimization, else test data\n",
    "\n",
    "    # Don't change these; the 'if' statements take care of them\n",
    "    # Set network parameters in NeuralNetwork class\n",
    "    fullAnglesVal = False\n",
    "    crosswireVal = False\n",
    "\n",
    "    if dataSetType==1:\n",
    "        if compFlag:\n",
    "            trainY = trainLabelPath+'mags.csv'\n",
    "            trainX = trainPath+geomPath+'readings.csv'\n",
    "            testY = testLabelPath+'mags.csv'\n",
    "            testX = testPath+geomPath+'readings.csv'\n",
    "        else:\n",
    "            trainY = 'MagTrain/mags.csv'\n",
    "            trainX = 'MagTrain/readings.csv'\n",
    "            testY = 'MagTest/mags.csv'\n",
    "            testX = 'MagTest/readings.csv'\n",
    "\n",
    "        training_data = WindMagDataset(trainY, trainX, transform=None)\n",
    "        testing_data = WindMagDataset(testY, testX, transform=None)\n",
    "        epochs = epochs0\n",
    "\n",
    "    elif dataSetType==2:\n",
    "        if compFlag:\n",
    "            trainY = trainLabelPath+'angsrad.csv'\n",
    "            trainX = trainPath+geomPath+'readings.csv'\n",
    "            testY = testLabelPath+'angsrad.csv'\n",
    "            testX = testPath+geomPath+'readings.csv'\n",
    "            fullAnglesVal = True\n",
    "\n",
    "        else:\n",
    "            trainY = 'MagTrain/angsrad.csv'\n",
    "            trainX = 'MagTrain/readings.csv'\n",
    "            testY = 'MagTest/angsrad.csv'\n",
    "            testX = 'MagTest/readings.csv'\n",
    "\n",
    "        training_data = WindAngDataset(trainY, trainX, transform=None)\n",
    "        testing_data = WindAngDataset(testY, testX, transform=None)\n",
    "        epochs = epochs0\n",
    "\n",
    "    elif dataSetType==3:\n",
    "        trainY1 = 'CrossTrain/crossmags.csv'\n",
    "        trainY2 = 'CrossTrain/crossangsrad.csv'\n",
    "        trainX = 'CrossTrain/crossreadings.csv'\n",
    "        testY1 = 'CrossTest/crossmags.csv'\n",
    "        testY2 = 'CrossTest/crossangsrad.csv'\n",
    "        testX = 'CrossTest/crossreadings.csv'\n",
    "\n",
    "        training_data = CrossWireDataset(trainY1, trainY2, trainX, transform=None)\n",
    "        testing_data = CrossWireDataset(testY1, testY2, testX, transform=None)\n",
    "        epochs = 2*epochs0\n",
    "\n",
    "        crosswireVal = True\n",
    "\n",
    "    elif dataSetType==4:\n",
    "\n",
    "        trainY = 'CrossTrain/crossmags.csv'\n",
    "        trainX = 'CrossTrain/crossreadings.csv'\n",
    "        testY = 'CrossTest/crossmags.csv'\n",
    "        testX = 'CrossTest/crossreadings.csv'\n",
    "\n",
    "        training_data = WindMagDataset(trainY, trainX, transform=None)\n",
    "        testing_data = WindMagDataset(testY, testX, transform=None)\n",
    "        epochs = epochs0\n",
    "\n",
    "    elif dataSetType==5:\n",
    "        trainY = 'CrossTrain/crossangsrad.csv'\n",
    "        trainX = 'CrossTrain/crossreadings.csv'\n",
    "        testY = 'CrossTest/crossangsrad.csv'\n",
    "        testX = 'CrossTest/crossreadings.csv'\n",
    "\n",
    "        training_data = WindAngDataset(trainY, trainX, transform=None)\n",
    "        testing_data = WindAngDataset(testY, testX, transform=None)\n",
    "        epochs = epochs0\n",
    "\n",
    "        fullAnglesVal = True\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Not a valid dataSetType index (must be in {1, 2, 3, 4, or 5})')\n",
    "\n",
    "    '''\n",
    "    # Make training and testing data\n",
    "    train_dataloader = DataLoader(training_data, batch_size=180, shuffle=True)\n",
    "    test_dataloader = DataLoader(testing_data, batch_size=72, shuffle=True)\n",
    "    model = NeuralNetwork(crosswire=crosswireVal, fullAngles=fullAnglesVal, geom=geometryVal)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    '''\n",
    "    \n",
    "    return training_data, testing_data, epochs, fullAnglesVal, crosswireVal, trainPath, trainLabelPath, testPath, testLabelPath, geomPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7906146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define needed learning quantities\n",
    "\n",
    "# Learning rate (initial)\n",
    "# ### Generally ~ 1e-3 for Adam\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Batch size (default 64)\n",
    "batch_size = 180\n",
    "\n",
    "# Number of training epochs for \n",
    "# ### the simpler regression problems\n",
    "epochs0 = 15\n",
    "\n",
    "# Loss Function (MSE/MAE usually because we are \n",
    "# running relatively standard regression)\n",
    "\n",
    "### ### Mean Squared error loss\n",
    "# loss_fn = nn.MSELoss()\n",
    "\n",
    "# Mean Absolute Error Loss\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# Verbose flag toggles training\n",
    "verboseFlag=False\n",
    "\n",
    "# training_data, testing_data, epochs, fullAnglesVal, crosswireVal, trainPath, testPath = makeDataset(dataSetType=2, geometryVal=3, compFlag=True, N=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3875eb0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NN = np.array([1, 2, 5])\n",
    "GEOMVAL = np.arange(3, 7)\n",
    "\n",
    "for ii in range(len(NN)):\n",
    "    for jj in range(len(GEOMVAL)):\n",
    "        N = NN[ii]\n",
    "        geometryVal = GEOMVAL[jj]\n",
    "        for kk in range(5):\n",
    "            np.random.seed(kk*12345 + 31415*N*(geometryVal**3))\n",
    "            # Make all necessary data\n",
    "            training_data, testing_data, epochs, fullAnglesVal, crosswireVal, trainPath, trainLabelPath, testPath, testLabelPath, geomPath = makeDataset(dataSetType=2, geometryVal=geometryVal, compFlag=True, N=N, epochs0=epochs0)\n",
    "            \n",
    "            # Make training and testing dataloaders\n",
    "            # Initialize model and optimizer params\n",
    "            train_dataloader = DataLoader(training_data, batch_size=180, shuffle=True)\n",
    "            test_dataloader = DataLoader(testing_data, batch_size=72, shuffle=True)\n",
    "            model = NeuralNetwork(crosswire=crosswireVal, fullAngles=fullAnglesVal, geom=geometryVal)\n",
    "            opt = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            avg_error = test_loop(test_dataloader, model, 0, kk, loss_fn, lastLoop=False, writePath=(testPath+geomPath))\n",
    "            \n",
    "            '''\n",
    "            for t in range(epochs):\n",
    "                print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "                train_loop(train_dataloader, model, opt, t, kk, loss_fn, verbose=verboseFlag, writePath=(testPath+geomPath))\n",
    "                print()\n",
    "                # if (float(t+1)/float(epochs) >= k or (t==(epochs-1))):\n",
    "                if t < epochs - 1:\n",
    "                    avg_error = test_loop(test_dataloader, model, t, kk, loss_fn, lastLoop=(t==(epochs-1)), writePath=(testPath+geomPath))\n",
    "                else: \n",
    "                    # avg_error, Z = test_loop(test_dataloader, model, loss_fn, lastLoop=(t==(epochs-1)))\n",
    "                    avg_error = test_loop(test_dataloader, model, t, kk, loss_fn, lastLoop=(t==(epochs-1)), writePath=(testPath+geomPath))\n",
    "            '''\n",
    "            # Print that we have finished training\n",
    "            print(f\"Finished seed: {kk+1:>2f} of 5, on geometry {jj+1:>2f} of 4, on filtering setting {ii+1:>2f} of 3 \\n\")\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b54426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triangle -- Best: ~20.6 degrees mean error; ~30 epochs; network layers 3-30-15-1; \n",
    "#          -- tested +10 more epochs and stalled in 20.9-21.5 test error range\n",
    "#\n",
    "# Square   -- ~4.5 degrees mean error; ~330 epochs; network layers [4]-50-25-1\n",
    "#          -- tested +00 more epochs, stalled in 6-6.5 range\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd80683",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zs = np.sort(Z)\n",
    "np.savetxt(testPath+geomPath+'ValErrorSort.csv', Zs, delimiter=',')\n",
    "\n",
    "print('Mean Absolute Error (deg): ', str(np.mean(Zs)*180.0/math.pi))\n",
    "\n",
    "# Choose what fraction of Zs to study\n",
    "fracPred = 0.98\n",
    "\n",
    "\n",
    "# Take the >fracPred set of best predictions\n",
    "nKeep = int(np.ceil(fracPred*len(Zs)))\n",
    "Zsmall = Zs[:nKeep]\n",
    "\n",
    "# Print the fracPred quantile worst prediction\n",
    "print(np.max(Zsmall))\n",
    "print('This is equivalent to '+ str(np.max(Zsmall)*180.0/math.pi) + ' degrees')\n",
    "print('Mean Absolute Error, best 98% (deg): ', str(np.mean(Zsmall)*180.0/math.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac89f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(2)\n",
    "plt.hist(Zsmall, cumulative=False, density=True, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821173b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = int(len(Zsmall)*0.84)\n",
    "print(zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2215d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Zsmall.shape)\n",
    "print(Zsmall[zs]*180/math.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = np.array([1, 2, 5])\n",
    "print(NN[0])\n",
    "print(NN.shape)\n",
    "GEOMVAL = np.arange(3, 7)\n",
    "print(GEOMVAL)\n",
    "print(GEOMVAL.shape)\n",
    "# training_data, testing_data, epochs, fullAnglesVal, crosswireVal, trainPath, testPath = makeDataset(dataSetType=2, geometryVal=3, compFlag=True, N=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361c33cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dataset\n",
    "# Change this as desired in {1, 2, 3, 4, 5}\n",
    "#\n",
    "# INDEX: \n",
    "#   --- (1) Sparse wind magnitudes                         [OLD]\n",
    "#   --- (2) Sparse wind angles (10-degree increments)      [OLD]\n",
    "#   --- (3) Dense Crosswire Model \n",
    "#   --- (4) Dense Wind Magnitudes \n",
    "#   --- (5) Dense Incidence Angles (2-degree increments)\n",
    "dataSetType = 2\n",
    "\n",
    "# 3=Triangle, 4=Square, 5=Pentagon, 6=Hexagon\n",
    "geometryVal = 3\n",
    "compFlag=True\n",
    "N = 1                 # Number of sequentially averaged data points\n",
    "\n",
    "if geometryVal == 3:\n",
    "    geomPath='tri/'\n",
    "elif geometryVal == 4:\n",
    "    geomPath='squ/'\n",
    "elif geometryVal == 5:\n",
    "    geomPath='pent/'\n",
    "elif geometryVal == 6:\n",
    "    geomPath='hex/'\n",
    "else:\n",
    "    raise ValueError('Geometry must be in {3, 4, 5, 6}')\n",
    "\n",
    "trainPath='compTrain_N'+str(N)+'/'\n",
    "testPath='compVal_N'+str(N)+'/'       # Set to validation data for network/hyperparameter optimization, else test data\n",
    "\n",
    "# Don't change these; the 'if' statements take care of them\n",
    "# Set network parameters in NeuralNetwork class\n",
    "fullAnglesVal = False\n",
    "crosswireVal = False\n",
    "\n",
    "if dataSetType==1:\n",
    "    if compFlag:\n",
    "        trainY = trainPath+geomPath+'mags.csv'\n",
    "        trainX = trainPath+geomPath+'readings.csv'\n",
    "        testY = testPath+geomPath+'mags.csv'\n",
    "        testX = testPath+geomPath+'readings.csv'\n",
    "    else:\n",
    "        trainY = 'MagTrain/mags.csv'\n",
    "        trainX = 'MagTrain/readings.csv'\n",
    "        testY = 'MagTest/mags.csv'\n",
    "        testX = 'MagTest/readings.csv'\n",
    "    \n",
    "    training_data = WindMagDataset(trainY, trainX, transform=None)\n",
    "    testing_data = WindMagDataset(testY, testX, transform=None)\n",
    "    epochs = epochs0\n",
    "    \n",
    "elif dataSetType==2:\n",
    "    if compFlag:\n",
    "        trainY = trainPath+geomPath+'angsrad.csv'\n",
    "        trainX = trainPath+geomPath+'readings.csv'\n",
    "        testY = testPath+geomPath+'angsrad.csv'\n",
    "        testX = testPath+geomPath+'readings.csv'\n",
    "        fullAnglesVal = True\n",
    "        \n",
    "    else:\n",
    "        trainY = 'MagTrain/angsrad.csv'\n",
    "        trainX = 'MagTrain/readings.csv'\n",
    "        testY = 'MagTest/angsrad.csv'\n",
    "        testX = 'MagTest/readings.csv'\n",
    "    \n",
    "    training_data = WindAngDataset(trainY, trainX, transform=None)\n",
    "    testing_data = WindAngDataset(testY, testX, transform=None)\n",
    "    epochs = epochs0\n",
    "    \n",
    "elif dataSetType==3:\n",
    "    trainY1 = 'CrossTrain/crossmags.csv'\n",
    "    trainY2 = 'CrossTrain/crossangsrad.csv'\n",
    "    trainX = 'CrossTrain/crossreadings.csv'\n",
    "    testY1 = 'CrossTest/crossmags.csv'\n",
    "    testY2 = 'CrossTest/crossangsrad.csv'\n",
    "    testX = 'CrossTest/crossreadings.csv'\n",
    "    \n",
    "    training_data = CrossWireDataset(trainY1, trainY2, trainX, transform=None)\n",
    "    testing_data = CrossWireDataset(testY1, testY2, testX, transform=None)\n",
    "    epochs = 2*epochs0\n",
    "    \n",
    "    crosswireVal = True\n",
    "    \n",
    "elif dataSetType==4:\n",
    "    \n",
    "    trainY = 'CrossTrain/crossmags.csv'\n",
    "    trainX = 'CrossTrain/crossreadings.csv'\n",
    "    testY = 'CrossTest/crossmags.csv'\n",
    "    testX = 'CrossTest/crossreadings.csv'\n",
    "    \n",
    "    training_data = WindMagDataset(trainY, trainX, transform=None)\n",
    "    testing_data = WindMagDataset(testY, testX, transform=None)\n",
    "    epochs = epochs0\n",
    "    \n",
    "elif dataSetType==5:\n",
    "    trainY = 'CrossTrain/crossangsrad.csv'\n",
    "    trainX = 'CrossTrain/crossreadings.csv'\n",
    "    testY = 'CrossTest/crossangsrad.csv'\n",
    "    testX = 'CrossTest/crossreadings.csv'\n",
    "    \n",
    "    training_data = WindAngDataset(trainY, trainX, transform=None)\n",
    "    testing_data = WindAngDataset(testY, testX, transform=None)\n",
    "    epochs = epochs0\n",
    "    \n",
    "    fullAnglesVal = True\n",
    "    \n",
    "else:\n",
    "    raise ValueError('Not a valid dataSetType index (must be in {1, 2, 3, 4, or 5})')\n",
    "    \n",
    "'''\n",
    "# Make training and testing data\n",
    "train_dataloader = DataLoader(training_data, batch_size=180, shuffle=True)\n",
    "test_dataloader = DataLoader(testing_data, batch_size=72, shuffle=True)\n",
    "model = NeuralNetwork(crosswire=crosswireVal, fullAngles=fullAnglesVal, geom=geometryVal)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951bb206",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
