{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd60277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ec50a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define speeds for 0-40 Hz\n",
    "speeds = np.array((0.00, 1.26363735, 1.58562983, 2.07066356, 2.571993, 3.18291372, 3.75322345, 4.33626595, 4.91413509))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e544d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossWireDataset(Dataset):\n",
    "    def __init__(self, magFile, angFile, readingsFile, transform=None, target_transform=None):\n",
    "        \n",
    "        # Construct the labels\n",
    "        tmpMag = pd.read_csv(magFile)\n",
    "        tmpAng = pd.read_csv(angFile)\n",
    "        self.mags = torch.Tensor(tmpMag.to_numpy())\n",
    "        self.angs = torch.Tensor(tmpAng.to_numpy())\n",
    "        \n",
    "        # Construct the features and place them into readings (X). \n",
    "        tmpReadings = pd.read_csv(readingsFile)\n",
    "        tmpReadings = tmpReadings.to_numpy()\n",
    "        print(tmpReadings.shape)\n",
    "        LL = tmpReadings.shape[0]\n",
    "        tmpReadings2 = np.zeros((LL, 3))\n",
    "        for k in range(LL):\n",
    "            tmpReadings2[k, 0] = np.max(np.abs(tmpReadings[k, :]))\n",
    "            tmpReadings2[k, 1] = np.argmax(np.abs(tmpReadings[k, :]))\n",
    "            tt = int(tmpReadings2[k,1])\n",
    "            tmpReadings2[k, 2] = np.abs(tmpReadings[k, (tt-1)%6])/(np.abs(tmpReadings[k, (tt+1)%6]) + 0.05)\n",
    "        self.readings = torch.Tensor(tmpReadings2)\n",
    "        self.transform=transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.mags)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        reading = self.readings[idx, :]\n",
    "        mag = self.mags[idx]\n",
    "        ang = self.angs[idx]\n",
    "        label = torch.cat((mag, ang), 0)\n",
    "        \n",
    "        if self.transform:\n",
    "            reading = self.transform(reading)\n",
    "        if self.target_transform:\n",
    "            mag = self.target_transform(mag)\n",
    "\n",
    "        return reading, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4ce0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindMagDataset(Dataset):\n",
    "    def __init__(self, magFile, readingsFile, transform=None, target_transform=None):\n",
    "        tmpMag = pd.read_csv(magFile)\n",
    "        tmpReadings = pd.read_csv(readingsFile)\n",
    "        self.mags = torch.Tensor(tmpMag.to_numpy())\n",
    "        self.readings = torch.Tensor(tmpReadings.to_numpy())\n",
    "        self.transform=transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.mags)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        reading = self.readings[idx, :]\n",
    "        mag = self.mags[idx]\n",
    "        if self.transform:\n",
    "            reading = self.transform(reading)\n",
    "        if self.target_transform:\n",
    "            mag = self.target_transform(mag)\n",
    "\n",
    "        return reading, mag\n",
    "\n",
    "class WindAngDataset(Dataset):\n",
    "    def __init__(self, angFile, readingsFile, transform=None, target_transform=None):\n",
    "        tmpAng = pd.read_csv(angFile)\n",
    "        tmpReadings = pd.read_csv(readingsFile)\n",
    "        self.angs = torch.Tensor(tmpAng.to_numpy())\n",
    "        self.readings = torch.Tensor(tmpReadings.to_numpy())\n",
    "        self.transform=transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.angs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        reading = self.readings[idx, :]\n",
    "        ang = self.angs[idx]\n",
    "        if self.transform:\n",
    "            reading = self.transform(reading)\n",
    "        if self.target_transform:\n",
    "            ang = self.target_transform(ang)\n",
    "\n",
    "        return reading, ang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9622d17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, crosswire=False, fullAngles=False):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        if crosswire:\n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(3, 25),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(25, 15),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(15, 2),\n",
    "            )\n",
    "        else:\n",
    "            if fullAngles:\n",
    "                self.linear_relu_stack = nn.Sequential(\n",
    "                    nn.Linear(6, 20),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(20, 8),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(8, 1),\n",
    "                )\n",
    "            else:\n",
    "                self.linear_relu_stack = nn.Sequential(\n",
    "                    nn.Linear(6, 10),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(10, 5),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(5, 1),\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45d72fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            # correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8498d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define miscellaneous learning quantities\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 8\n",
    "loss_fn = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cbd206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ba8a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make CrossWire Dataset\n",
    "training_data3 = CrossWireDataset('CrossTrain/crossmags.csv', 'CrossTrain/crossangsrad.csv', 'CrossTrain/crossreadings.csv', transform=None)\n",
    "train_dataloader3 = DataLoader(training_data3, batch_size=64, shuffle=True)\n",
    "testing_data3 = CrossWireDataset('CrossTest/crossmags.csv', 'CrossTest/crossangsrad.csv', 'CrossTest/crossreadings.csv', transform=None)\n",
    "test_dataloader3 = DataLoader(testing_data3, batch_size=64, shuffle=True)\n",
    "\n",
    "# train_features, train_labels = next(iter(train_dataloader))\n",
    "# print(f\"Feature batch shape: {train_features.size()}\")\n",
    "# print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "crossModel = NeuralNetwork(crosswire=True)\n",
    "\n",
    "optimizerCross = torch.optim.Adam(crossModel.parameters(), lr=learning_rate)\n",
    "\n",
    "X = torch.rand(1, 3)\n",
    "logits = crossModel(X)\n",
    "print(logits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7ab128",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader3, crossModel, loss_fn, optimizerCross)\n",
    "    test_loop(test_dataloader3, crossModel, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6318c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151b35c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make fullMag Data\n",
    "training_data4 = WindMagDataset('CrossTrain/crossmags.csv', 'CrossTrain/crossreadings.csv', transform=None)\n",
    "train_dataloader4 = DataLoader(training_data4, batch_size=64, shuffle=True)\n",
    "testing_data4 = WindMagDataset('CrossTest/crossmags.csv', 'CrossTest/crossreadings.csv', transform=None)\n",
    "test_dataloader4 = DataLoader(testing_data4, batch_size=64, shuffle=True)\n",
    "\n",
    "# train_features, train_labels = next(iter(train_dataloader))\n",
    "# print(f\"Feature batch shape: {train_features.size()}\")\n",
    "# print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "fullMagModel = NeuralNetwork()\n",
    "\n",
    "optimizerFullMag = torch.optim.Adam(fullMagModel.parameters(), lr=learning_rate)\n",
    "\n",
    "X = torch.rand(1, 6)\n",
    "logits = fullMagModel(X)\n",
    "print(logits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b47fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader4, fullMagModel, loss_fn, optimizerFullMag)\n",
    "    test_loop(test_dataloader4, fullMagModel, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4560136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make fullAng Data\n",
    "training_data5 = WindAngDataset('CrossTrain/crossangsrad.csv', 'CrossTrain/crossreadings.csv', transform=None)\n",
    "train_dataloader5 = DataLoader(training_data5, batch_size=64, shuffle=True)\n",
    "testing_data5 = WindAngDataset('CrossTest/crossangsrad.csv', 'CrossTest/crossreadings.csv', transform=None)\n",
    "test_dataloader5 = DataLoader(testing_data5, batch_size=64, shuffle=True)\n",
    "\n",
    "# train_features, train_labels = next(iter(train_dataloader))\n",
    "# print(f\"Feature batch shape: {train_features.size()}\")\n",
    "# print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "fullAngModel = NeuralNetwork(fullAngles=True)\n",
    "\n",
    "optimizerFullAng = torch.optim.Adam(fullAngModel.parameters(), lr=learning_rate)\n",
    "\n",
    "X = torch.rand(1, 6)\n",
    "logits = fullAngModel(X)\n",
    "print(logits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57b9fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader5, fullAngModel, loss_fn, optimizerFullAng)\n",
    "    test_loop(test_dataloader5, fullAngModel, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58983d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b9c173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36be394a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a4a2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Wind Mag Data\n",
    "training_data = WindMagDataset('MagTrain/mags.csv', 'MagTrain/readings.csv', transform=None)\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "testing_data = WindMagDataset('MagTest/mags.csv', 'MagTest/readings.csv', transform=None)\n",
    "test_dataloader = DataLoader(testing_data, batch_size=64, shuffle=True)\n",
    "\n",
    "# train_features, train_labels = next(iter(train_dataloader))\n",
    "# print(f\"Feature batch shape: {train_features.size()}\")\n",
    "# print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "magModel = NeuralNetwork()\n",
    "\n",
    "optimizerMag = torch.optim.Adam(magModel.parameters(), lr=learning_rate)\n",
    "\n",
    "X = torch.rand(1, 6)\n",
    "logits = magModel(X)\n",
    "print(logits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edc1afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 7\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, magModel, loss_fn, optimizerMag)\n",
    "    test_loop(test_dataloader, magModel, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0025f3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418dcc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Wind Mag Data\n",
    "training_data2 = WindAngDataset('MagTrain/angsrad.csv', 'MagTrain/readings.csv', transform=None)\n",
    "train_dataloader2 = DataLoader(training_data2, batch_size=64, shuffle=True)\n",
    "testing_data2 = WindAngDataset('MagTest/angsrad.csv', 'MagTest/readings.csv', transform=None)\n",
    "test_dataloader2 = DataLoader(testing_data2, batch_size=64, shuffle=True)\n",
    "\n",
    "angModel = NeuralNetwork()\n",
    "optimizerAng = torch.optim.Adam(angModel.parameters(), lr=learning_rate)\n",
    "X = torch.rand(1, 6)\n",
    "logits = angModel(X)\n",
    "print(logits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69595992",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader2, angModel, loss_fn, optimizerAng)\n",
    "    test_loop(test_dataloader2, angModel, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
