{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes for saving and loading Pytorch Models, from \n",
    "# https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "'''\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "optimizer = TheOptimizerClass(*args, **kwargs)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.eval()\n",
    "# - or -\n",
    "model.train()\n",
    "'''\n",
    "# Useful reference for saving off weights, etc, that we might need and/or want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customLoss():\n",
    "    def __init__(self):\n",
    "        self.pi = math.pi\n",
    "        \n",
    "    def forward(self, y, yhat):\n",
    "        self.Errs = torch.cat((torch.remainder(y-yhat, 2.0*self.pi), torch.sub(torch.remainder(y-yhat, 2.0*self.pi), 2.0*self.pi)), 1)\n",
    "        tmp1 = torch.min(torch.abs(self.Errs), 1).values\n",
    "        return torch.sum(tmp1)\n",
    "        # return torch.sum(torch.min(torch.abs(torch.tensor([self.Errs, self.Errs-2.0*math.pi])), 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define needed learning quantities\n",
    "\n",
    "# Learning rate (initial)\n",
    "# ### Generally ~ 1e-3 for Adam\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Batch size (default 64)\n",
    "batch_size_train = 180\n",
    "batch_size_test = int(0.4*batch_size_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, optimizer, epochNum, seedNum, loss_fn=nn.L1Loss(), verbose=True, batch_size=180, writePath=None, loocv=None):\n",
    "    \"\"\"\n",
    "    Loop for training a 'model' (class NeuralNetwork) on data stored in 'dataloader,' using loss function\n",
    "    'loss_fn' and optimizer method 'optimizer'\n",
    "    \n",
    "    [Inputs]\n",
    "    dataloader    -- type DataLoader    -- Pytorch DataLoader object to facilitate training/testing data storage\n",
    "                                           to interface with pytorch optimization and training modules\n",
    "                                           \n",
    "    model         -- type NeuralNetwork -- Pytorch NeuralNetwork object to facilitate training/testing of speed and \n",
    "                                           angle prediction for FlowDrone\n",
    "                                           \n",
    "    epochNum      -- type int           -- Current epoch number to track training loss\n",
    "    \n",
    "    seedNum       -- type int           -- Seed of the current run (to average over to demonstrate convergence)\n",
    "    \n",
    "    loss_fn       -- type torch.nn loss -- Pytorch loss function (in nn library) for training the speed/angle predictor\n",
    "                                           for FlowDrone. Defaults to nn.MSELoss() because we are regressing real-valued\n",
    "                                           variables. \n",
    "                                           \n",
    "    optimizer     -- type torch.optim   -- Pytorch optimizer for ANN weight updates. Normally will use ADAM unless there\n",
    "                                           is a compelling reason to deviate. \n",
    "    \n",
    "    verbose       -- type Boolean       -- Toggles printing of training loss during training. Default is TRUE. \n",
    "    \n",
    "    writePath     -- type String        -- If present, a path to write to a csv file in order \n",
    "    [Outputs]\n",
    "    \n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    f = open(writePath+'trainCost'+str(seedNum)+'.csv', 'a') if loocv is None else open(writePath+'valCost'+str(seedNum)+'_'+str(loocv)+'.csv', 'a')\n",
    "    writer = csv.writer(f)\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        '''\n",
    "        for k in range(pred.shape[0]):\n",
    "            if ((pred[k, -1] - y[k, -1]) >= math.pi):\n",
    "                while ((pred[k, -1] - y[k, -1]) >= math.pi):\n",
    "                    pred[k, -1] -= 2.0*math.pi\n",
    "            elif ((pred[k, -1] - y[k, -1]) <= -math.pi):\n",
    "                pred[k, -1] = (pred[k,-1])%(2.0*math.pi)\n",
    "        '''\n",
    "        loss = loss_fn.forward(y, pred)\n",
    "        loss_average = (loss/pred.shape[0]).cpu().detach().numpy()\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 200 == 199 or (batch==0 and epochNum==1):\n",
    "            if verbose:\n",
    "                loss, current = loss.item(), batch * len(X)\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "            if writePath is None:\n",
    "                pass\n",
    "            else: \n",
    "                writer.writerow(np.array([(batch + (np.ceil(size/batch_size)*epochNum)), 180.0*loss_average/math.pi]))\n",
    "                \n",
    "\n",
    "    # close the file\n",
    "    f.close()\n",
    "    return \n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, epochNum, seedNum, loss_fn=nn.L1Loss(), lastLoop=False, writePath=None, loocv=None):\n",
    "    \"\"\"\n",
    "    Loop for test a 'model' (class NeuralNetwork) on data stored in 'dataloader,' using loss function\n",
    "    'loss_fn.'\n",
    "    \n",
    "    [Inputs]\n",
    "    dataloader    -- type DataLoader    -- Pytorch DataLoader object to facilitate training/testing data storage\n",
    "                                           to interface with pytorch optimization and training modules\n",
    "                                           \n",
    "    model         -- type NeuralNetwork -- Pytorch NeuralNetwork object to facilitate training/testing of speed and \n",
    "                                           angle prediction for FlowDrone\n",
    "\n",
    "    epochNum      -- type Int           -- Current epoch\n",
    "    \n",
    "    loss_fn       -- type torch.nn loss -- Pytorch loss function (in nn library) for training the speed/angle predictor\n",
    "                                           for FlowDrone. Defaults to nn.MSELoss() because we are regressing real-valued\n",
    "                                           variables. \n",
    "                                           \n",
    "    lastLoop      -- type Boolean       -- Whether we are on the last epoch (for histogram information)\n",
    "    \n",
    "    writePath     -- type String        -- File to write to\n",
    "    [Outputs]\n",
    "    \n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    batch_size = dataloader.batch_size\n",
    "    hists = False\n",
    "    \n",
    "    if lastLoop:\n",
    "        if (num_batches == size):\n",
    "            print('On the last loop!')\n",
    "            errs = np.zeros((size, 2))\n",
    "            idxVal = 0\n",
    "            hists = True\n",
    "        \n",
    "    test_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            '''\n",
    "            for k in range(pred.shape[0]):\n",
    "                if ((pred[k, -1] - y[k, -1]) >= math.pi):\n",
    "                    while ((pred[k, -1] - y[k, -1]) >= math.pi):\n",
    "                        pred[k, -1] -= 2.0*math.pi\n",
    "                elif ((pred[k, -1] - y[k, -1]) <= -math.pi):\n",
    "                    pred[k, -1] = (pred[k,-1])%(2.0*math.pi)\n",
    "            '''\n",
    "            if hists:\n",
    "                errs[idxVal, :] = np.array([y, loss_fn.forward(y, pred)])\n",
    "                # errs[idxVal, :] = np.array([y, loss_fn(y, pred).item()])\n",
    "                test_loss += errs[idxVal, 1]\n",
    "                idxVal += 1\n",
    "            else:\n",
    "                test_loss += loss_fn.forward(y, pred)/pred.shape[0]\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    if loocv is None:\n",
    "        print(f\"Avg loss (rad): {test_loss:>8f}\")\n",
    "        print(f\"Avg error (deg): {(test_loss*180.0/math.pi):>8f} \\n\")\n",
    "    else: \n",
    "        print(f\"Avg loss/error (m/s): {test_loss:>8f}\")\n",
    "\n",
    "    if writePath is None:\n",
    "        pass\n",
    "    else:\n",
    "        # open the file\n",
    "        f = open(writePath+'testCost'+str(seedNum)+'.csv', 'a') if loocv is None else open(writePath+'valCost'+str(seedNum)+'_'+str(loocv)+'.csv', 'a')\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        # write out the relevant cost\n",
    "        writer.writerow(np.array([epochNum, test_loss*180.0/math.pi]))\n",
    "                \n",
    "        # close the file\n",
    "        f.close()\n",
    "    \n",
    "    if hists:\n",
    "        if loocv is None:\n",
    "            np.savetxt(writePath+'testErrs'+str(seedNum)+'.csv', errs, delimiter=',')\n",
    "        else: \n",
    "            np.savetxt(writePath+'valErrs'+str(seedNum)+'_'+str(loocv)+'.csv', errs, delimiter=',')\n",
    "        \n",
    "        return test_loss, errs\n",
    "    \n",
    "    else: \n",
    "        return test_loss\n",
    "\n",
    "#\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
